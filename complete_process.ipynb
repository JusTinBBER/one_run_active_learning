{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用到的套件\n",
    "\n",
    "\n",
    "from __future__ import print_function, division\n",
    "import os  \n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "import torchvision\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "from pathlib import Path\n",
    "from torchvision import datasets,transforms\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import time\n",
    "import argparse\n",
    "from time import sleep\n",
    "from tqdm import tqdm, trange\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as FUN\n",
    "from scipy import io\n",
    "import efficientnet_pytorch\n",
    "import torchvision.transforms as T\n",
    "import PIL\n",
    "import pickle\n",
    "import torchvision.datasets as dsets\n",
    "from scipy.misc import imsave\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定義function\n",
    "\n",
    "def load_file(filename):\n",
    "    with open(filename, 'rb') as fo:\n",
    "        data = pickle.load(fo, encoding='latin1')\n",
    "    return data\n",
    "\n",
    "# 解壓縮，返回解壓後的字典\n",
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "#補邊,填充成正方形，防止resize變形\n",
    "def expend_img(img):\n",
    "    '''\n",
    "    :param img: 图片数据\n",
    "    :return:\n",
    "    '''\n",
    "    fill_pix=[0,0,0] #填充色素，可自己設定\n",
    "    h,w=img.shape[:2]\n",
    "    if h>=w: #左右填充\n",
    "        padd_width=int(h-w)//2\n",
    "        padd_top,padd_bottom,padd_left,padd_right=0,0,padd_width,padd_width #各個方向的填充像素\n",
    "    elif h<w: #上下填充\n",
    "        padd_high=int(w-h)//2\n",
    "        padd_top,padd_bottom,padd_left,padd_right=padd_high,padd_high,0,0 #各個方向的填充像素\n",
    "    new_img = cv2.copyMakeBorder(img,padd_top,padd_bottom,padd_left,padd_right,cv2.BORDER_CONSTANT, value=fill_pix)\n",
    "    return new_img\n",
    "\n",
    "#對影像做基本的旋轉 和亮度 對比度 飽和度的調整\n",
    "def expend1_img(img):\n",
    "    '''\n",
    "    :param img: 圖片數據\n",
    "    :return:\n",
    "    '''\n",
    "    a = random.random()\n",
    "    \n",
    "    t2 = transforms.RandomHorizontalFlip(p=0.5)  # 水平镜像，p是機率\n",
    "    t3 = transforms.RandomVerticalFlip(p=0.2) #垂直鏡像\n",
    "    # print(type(img))\n",
    "    img = t2(img)\n",
    "    img = t3(img)\n",
    "    if a<0.4:\n",
    "        t1 = transforms.RandomRotation(45)  # 随機旋轉，旋轉範圍為【-45,45】\n",
    "        img = t1(img)\n",
    "\n",
    "    t4 = transforms.ColorJitter(brightness=(0.8,1.5), contrast=(0.8,1.5), saturation=(0.8,1.5))#調整亮度  對比度  飽和度\n",
    "    img = t4(img)\n",
    "    return img\n",
    "\n",
    "#對圖片做透視轉換\n",
    "def expend2_img(img):\n",
    "    t = transforms.RandomPerspective(distortion_scale=0.6,p=1,interpolation = 2,fill=0) #圖片透視化\n",
    "    img2 = t(img)\n",
    "    return img2\n",
    "\n",
    "#切分訓練集和測試集，並進行補邊處理\n",
    "def split_train_test(img_dir,save_dir,train_val_num):\n",
    "    '''\n",
    "    :param img_dir: 原始图片路径，注意是所有类别所在文件夹的上一级目录\n",
    "    :param save_dir: 保存图片路径\n",
    "    :param train_val_num: 切分比例\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    img_dir_list=glob.glob(img_dir+os.sep+\"*\")#獲取每個類别所在的路徑（一個類别對應一個文件夾）\n",
    "    for class_dir in img_dir_list:\n",
    "        class_name=class_dir.split(os.sep)[-1] #獲取當前類别\n",
    "        img_list=glob.glob(class_dir+os.sep+\"*\") #獲取每個類别文件夾下的所有圖片\n",
    "        all_num=len(img_list) #獲取總個數\n",
    "        train_list=random.sample(img_list,int(all_num*train_val_num)) #訓練集圖片所在路徑\n",
    "        save_train=save_dir+os.sep+'train'+os.sep+class_name\n",
    "        save_val=save_dir+os.sep+\"val\"+os.sep+class_name\n",
    "        os.makedirs(save_train,exist_ok=True)\n",
    "        os.makedirs(save_val,exist_ok=True) #建立對應的文件夾\n",
    "        #保存切分好的數據集\n",
    "        for imgpath in img_list:\n",
    "            imgname=Path(imgpath).name #獲取文件名\n",
    "            if imgpath in train_list:\n",
    "                img=cv2.imread(imgpath)\n",
    "                new_img=expend_img(img)\n",
    "                cv2.imwrite(save_train+os.sep+imgname,new_img)\n",
    "            else: #將除了訓練集意外的數據均視為驗證集\n",
    "                img = cv2.imread(imgpath)\n",
    "                new_img = expend_img(img)\n",
    "                cv2.imwrite(save_val + os.sep + imgname, new_img)\n",
    "                \n",
    "    print(\"split train and val finished !\")\n",
    "\n",
    "#資料增強\n",
    "def data_enhancement(img_dir,save_dir,train_val_num):\n",
    "\n",
    "    img_dir_list=glob.glob(img_dir+os.sep+\"*\")#獲取每个類别所在的路徑（一個類别對應一個文件夾）\n",
    "    for class_dir in img_dir_list:\n",
    "        class_name=class_dir.split(os.sep)[-1] #獲取當前類别\n",
    "        img_list=glob.glob(class_dir+os.sep+\"*\") #獲取每個類别文件夾下的所有圖片\n",
    "        all_num=len(img_list) #獲取總個數\n",
    "        train_list=random.sample(img_list,int(all_num*train_val_num)) #訓練集圖片所在路徑\n",
    "        save_train=save_dir+os.sep+\"train\"+os.sep+class_name\n",
    "        save_val=save_dir+os.sep+\"val\"+os.sep+class_name\n",
    "        os.makedirs(save_train,exist_ok=True)\n",
    "        os.makedirs(save_val,exist_ok=True) #建立對應的文件夾\n",
    "        # print(class_name+\" trian num\",len(train_list))\n",
    "        # print(class_name+\" val num\",all_num-len(train_list))\n",
    "        #保存切分好的數據集\n",
    "        for imgpath in img_list:\n",
    "            imgname=Path(imgpath).name #獲取文件名\n",
    "            if imgpath in train_list:\n",
    "                img= Image.open(imgpath)\n",
    "                for time in range(3):\n",
    "                    new_img=expend1_img(img)\n",
    "                    Image.Image.save(new_img,save_train+os.sep+str(time)+imgname)\n",
    "\n",
    "#資料增強( 透視轉換 )\n",
    "def perspective_transform(img_dir,save_dir,train_val_num):\n",
    "    \n",
    "    img_dir_list=glob.glob(img_dir+os.sep+\"*\")#獲取每个類别所在的路徑（一個類别對應一個文件夾）\n",
    "    for class_dir in img_dir_list:\n",
    "        class_name=class_dir.split(os.sep)[-1] #獲取當前類别\n",
    "        img_list=glob.glob(class_dir+os.sep+\"*\") #獲取每個類别文件夾下的所有圖片\n",
    "        all_num=len(img_list) #獲取總個數\n",
    "        train_list=random.sample(img_list,int(all_num*train_val_num)) #訓練集圖片所在路徑\n",
    "        save_train=save_dir+os.sep+\"train\"+os.sep+class_name\n",
    "        save_val=save_dir+os.sep+\"val\"+os.sep+class_name\n",
    "        os.makedirs(save_train,exist_ok=True)\n",
    "        os.makedirs(save_val,exist_ok=True) #建立對應的文件夾\n",
    "        # print(class_name+\" trian num\",len(train_list))\n",
    "        # print(class_name+\" val num\",all_num-len(train_list))\n",
    "        #保存切分好的數據集\n",
    "        for imgpath in img_list:\n",
    "            imgname=Path(imgpath).name #獲取文件名\n",
    "            if imgpath in train_list:\n",
    "                img= Image.open(imgpath)\n",
    "                for time in range(1):\n",
    "                    img2 = expend2_img(img)\n",
    "                    Image.Image.save(img2,save_train+os.sep+str(time)+'_per_'+imgname)\n",
    "\n",
    "#efficientionnet訓練模型\n",
    "class Efficientnet_train():\n",
    "    def __init__(self,opt):\n",
    "        self.epochs=opt.epochs #訓練週期\n",
    "        self.batch_size=opt.batch_size #batch_size\n",
    "        self.class_num=opt.class_num #類别數\n",
    "        self.imgsz=opt.imgsz #圖片尺寸\n",
    "        self.img_dir=opt.img_dir #圖片路徑\n",
    "        self.weights=opt.weights #模型路徑\n",
    "        self.save_dir=opt.save_dir #保存模型路徑\n",
    "        self.save_model_name=opt.save_model_name #保存模型檔名\n",
    "        self.lr=opt.lr #初始化學習率\n",
    "        self.moment=opt.m #動量\n",
    "        base_model = EfficientNet.from_name('efficientnet-b5') #加載模型，使用b幾的就改為b幾\n",
    "        state_dict = torch.load(self.weights)\n",
    "        base_model.load_state_dict(state_dict)\n",
    "        # 修改全連接層\n",
    "        num_ftrs = base_model._fc.in_features\n",
    "        base_model._fc = nn.Linear(num_ftrs, self.class_num)\n",
    "        print(device)\n",
    "        self.model = base_model.to(device)\n",
    "        # 交叉熵損失函數\n",
    "        self.cross = nn.CrossEntropyLoss()\n",
    "        # 優化器\n",
    "        self.optimzer = optim.SGD((self.model.parameters()), lr=self.lr, momentum=self.moment, weight_decay=0.0004)\n",
    "\n",
    "        #獲取處理後的數據集和類别映射表\n",
    "        self.trainx,self.valx,self.b=self.process()\n",
    "        print(self.b)\n",
    "    def __call__(self):\n",
    "        best_acc = 0\n",
    "        self.model.train(True)\n",
    "        for ech in tqdm(range(self.epochs)):\n",
    "            optimzer1 = self.lrfn(ech, self.optimzer)\n",
    "\n",
    "            print(\"----------Start Train Epoch %d----------\" % (ech + 1))\n",
    "            # 開始訓練\n",
    "            run_loss = 0.0  # 損失\n",
    "            run_correct = 0.0  # 準確率\n",
    "            count = 0.0  # 分類正確的個數\n",
    "\n",
    "            for i, data in enumerate(self.trainx):\n",
    "                # print('train')\n",
    "                inputs, label = data\n",
    "                inputs, label = inputs.to(device), label.to(device)\n",
    "\n",
    "                # 訓練\n",
    "                optimzer1.zero_grad()\n",
    "                output = self.model(inputs)\n",
    "\n",
    "                loss = self.cross(output, label)\n",
    "                loss.backward()\n",
    "                optimzer1.step()\n",
    "\n",
    "                run_loss += loss.item()  # 損失累加\n",
    "                _, pred = torch.max(output.data, 1)\n",
    "                count += label.size(0)  # 求總共的訓練個數\n",
    "                run_correct += pred.eq(label.data).cpu().sum()  # 截止當前預測正確的個數\n",
    "                #每隔100個batch顯示一次信息，這裡顯示的ACC是當前預測正確的個數/當前訓練過的個數\n",
    "                if (i+1)%100==0:\n",
    "                    print('[Epoch:{}__iter:{}/{}] | Acc:{}'.format(ech + 1,i+1,len(self.trainx), run_correct/count))\n",
    "            # print(run_correct,'------------',count)\n",
    "            train_acc = run_correct / count\n",
    "            # 每次訓完一批顯示一次信息\n",
    "            print('Epoch:{} | Loss:{} | Acc:{}'.format(ech + 1, run_loss / len(self.trainx), train_acc))\n",
    "\n",
    "            # 訓完一批次後進行驗證\n",
    "            print(\"----------Waiting Test Epoch {}----------\".format(ech + 1))\n",
    "            with torch.no_grad():\n",
    "                correct = 0.  # 預測正確的個數\n",
    "                total = 0.  # 總個數\n",
    "                for inputs, labels in self.valx:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    outputs = self.model(inputs)\n",
    "\n",
    "                    # 穫取最高分的那個類的索引\n",
    "                    _, pred = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += pred.eq(labels).cpu().sum()\n",
    "                test_acc = correct / total\n",
    "                print(\"批次%d的验证集准确率\" % (ech + 1), correct / total)\n",
    "            if best_acc < test_acc:\n",
    "                best_acc = test_acc\n",
    "                start_time=(time.strftime(\"%m%d\",time.localtime()))\n",
    "                save_weight=self.save_dir+os.sep+start_time #保存路徑\n",
    "                os.makedirs(save_weight,exist_ok=True)\n",
    "                torch.save(self.model.state_dict(), save_weight + os.sep + self.save_model_name)#不加state_dict()存法會直接把模型架構和權重一起存入weight檔中\n",
    "                                                                                                       #加state_dict()則只單純存權重(不易報錯)\n",
    "\n",
    "  #數據處理\n",
    "    def process(self):\n",
    "        # 數據增强\n",
    "        data_transforms = {\n",
    "            'train': transforms.Compose([\n",
    "                transforms.Resize((self.imgsz, self.imgsz)),  # resize\n",
    "                transforms.CenterCrop((self.imgsz, self.imgsz)),  # 中心裁剪\n",
    "                transforms.RandomRotation(45),  # 随機旋轉，旋轉範圍為【-45,45】\n",
    "                transforms.ToTensor(),  # 轉換為張量\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 標準化\n",
    "            ]),\n",
    "            \"val\": transforms.Compose([\n",
    "                transforms.Resize((self.imgsz, self.imgsz)),  # resize\n",
    "                transforms.CenterCrop((self.imgsz, self.imgsz)),  # 中心裁剪\n",
    "                transforms.ToTensor(),  # 張量轉換\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        }\n",
    "\n",
    "        # 定義圖像生成器\n",
    "        image_datasets = {x: datasets.ImageFolder(root=os.path.join(self.img_dir,x), transform=data_transforms[x]) for x in ['train', 'val']}\n",
    "\n",
    "        # 得到訓練集和驗證集\n",
    "        trainx = DataLoader(image_datasets[\"train\"], batch_size=self.batch_size, shuffle=True, drop_last=True)\n",
    "        valx = DataLoader(image_datasets[\"val\"], batch_size=self.batch_size, shuffle=True, drop_last=False)\n",
    "        b = image_datasets[\"train\"].class_to_idx  # id和類别對\n",
    "        return trainx,valx,b\n",
    "\n",
    "\n",
    "    # 學習率慢热加下降\n",
    "    def lrfn(self,num_epoch, optimzer):\n",
    "        lr_start = 0.00001  # 初始值\n",
    "        max_lr = 0.0004  # 最大值\n",
    "        lr_up_epoch = 10  # 學習率上升10个epoch\n",
    "        lr_sustain_epoch = 5  # 學習率保持不變\n",
    "        lr_exp = .8  # 衰减因子\n",
    "        if num_epoch < lr_up_epoch:  # 0-10个epoch學習率線性增加\n",
    "            lr = (max_lr - lr_start) / lr_up_epoch * num_epoch + lr_start\n",
    "        elif num_epoch < lr_up_epoch + lr_sustain_epoch:  # 學習率保持不變\n",
    "            lr = max_lr\n",
    "        else:  # 指數下降\n",
    "            lr = (max_lr - lr_start) * lr_exp ** (num_epoch - lr_up_epoch - lr_sustain_epoch) + lr_start\n",
    "        for param_group in optimzer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        return optimzer\n",
    "\n",
    "#分類網路 function\n",
    "\n",
    "class Residual(nn.Module):  \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Residual, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=1)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=2, stride=1)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        self.conv4res = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=2, stride=1)\n",
    "        self.AvgPool1d=nn.AdaptiveAvgPool1d(12)\n",
    "        self.bn4res = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \n",
    "        Y1 = self.conv4res(X)\n",
    "        Y1 = self.bn4res(Y1)\n",
    "\n",
    "        Y2 = self.bn1(self.conv1(X))\n",
    "\n",
    "        Y2 = F.relu(Y2)\n",
    "\n",
    "        Y2 = self.bn2(self.conv2(Y2))\n",
    "\n",
    "        Y2 = F.relu(Y2)\n",
    "\n",
    "        return Y1 + Y2\n",
    "\n",
    "def resnet_block(in_channels, out_channels, num_residuals):\n",
    "\n",
    "    blk = []\n",
    "    for i in range(num_residuals):\n",
    "        blk.append(Residual(in_channels, out_channels))\n",
    "\n",
    "    return nn.Sequential(*blk)\n",
    "\n",
    "class LSTM_FCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, layers):\n",
    "        super(LSTM_FCN, self).__init__()\n",
    "        # LSTM\n",
    "        self.conv4lstm = nn.Conv1d(48, 48, kernel_size=2, stride=2)\n",
    "        self.rnn = torch.nn.LSTM(input_dim, hidden_dim, num_layers=layers, batch_first=True)\n",
    "\n",
    "        # 1D conv\n",
    "        self.conv1 = nn.Conv1d(1, 256, kernel_size=2, stride=2)\n",
    "        self.res_block=resnet_block(in_channels=256,out_channels=256,num_residuals=3)\n",
    "        self.conv2 = nn.Conv1d(256, 16, kernel_size=1, stride=1)\n",
    "        self.AvgPool1d=nn.AdaptiveAvgPool1d(48) # length\n",
    "\n",
    "        # concat softmax\n",
    "        self.fc1 = nn.Linear(768, 256, bias=True)\n",
    "        self.dropou1=nn.Dropout(0.7)\n",
    "        self.fc2 = nn.Linear(256, 64, bias=False)\n",
    "        self.dropou2=nn.Dropout(0.7)\n",
    "        self.fc3 = nn.Linear(64, output_dim, bias=False)\n",
    "        self.softmax=nn.Softmax(dim=1)\n",
    "\n",
    "    def init_model(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (torch.nn.Linear, torch.nn.Conv1d)):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "        print(\"init success !!\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        \n",
    "        \n",
    "        # x=torch.unsqueeze(x,0)\n",
    "        # 1D cnn\n",
    "        cnn_out=self.conv1(x)\n",
    "        cnn_out=self.res_block(cnn_out)\n",
    "        cnn_out=self.conv2(cnn_out)\n",
    "        cnn_out=self.AvgPool1d(cnn_out)            \n",
    "\n",
    "        y=torch.flatten(cnn_out,start_dim=1)\n",
    "   \n",
    "        y = self.fc1(y) \n",
    "        y=self.dropou1(y)\n",
    "  \n",
    "        y = self.fc2(y) \n",
    "        y=self.dropou2(y)\n",
    "        y = self.fc3(y) \n",
    "\n",
    "        y= self.softmax(y)\n",
    " \n",
    "        return y\n",
    "\n",
    "'''算entropy'''\n",
    "def entropy(input):\n",
    "    all = 0\n",
    "    for t in range(len(input)):\n",
    "        if input[t]>=0:\n",
    "            en = -(input[t]*math.log(input[t],2))\n",
    "            all = all+en\n",
    "    return all\n",
    "\n",
    "\n",
    "# Load Test images\n",
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor\n",
    "\n",
    "\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    def __init__(self, *args):\n",
    "        super(ImageFolderWithPaths, self).__init__(*args)\n",
    "        self.trans = args[1]\n",
    "    def __len__(self):\n",
    "      return len(self.imgs)\n",
    "    def __getitem__(self, index):\n",
    "        img, label = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        \n",
    "        path = self.imgs[index][0]\n",
    "        return (img, label ,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將data分到對應的類別的資料夾\n",
    "\n",
    "img_dir = 'cifar_100/all'\n",
    "img_path_list = glob.glob(img_dir+os.sep+\"*\")\n",
    "img_list= os.listdir(img_dir)\n",
    "save_dir = 'cifar_100/train_class'\n",
    "\n",
    "# for t in range(100):\n",
    "#     os.makedirs(save_dir+'/'+str(t),exist_ok=True)\n",
    "\n",
    "with open('cifar_100/train_label.txt','r') as f :\n",
    "    img_path = f.read()\n",
    "\n",
    "img_path_list = img_path.splitlines()\n",
    "\n",
    "count = 0\n",
    "for path in img_path_list:\n",
    "    a = path.split(' ')\n",
    "    img=cv2.imread(img_dir+'/'+a[0]+'.png')\n",
    "    try:\n",
    "        new_img=expend_img(img)\n",
    "    except:\n",
    "        pass\n",
    "    cv2.imwrite(save_dir+'/'+a[1]+'/'+a[0]+'.png',new_img)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將train資料集取出10%，和5% 5%分開\n",
    "\n",
    "img_dir = 'cifar_100/train_class/train'\n",
    "save_dir = 'cifar_100\\cifar100_50percent_og/train'\n",
    "save_dir2 = 'cifar_100\\cifar100_50percent_og/train'\n",
    "train_val_num = 0.5\n",
    "\n",
    "img_dir_list=glob.glob(img_dir+os.sep+\"*\")#獲取每個類别所在的路徑（一個類别對應一個文件夾）\n",
    "for class_dir in img_dir_list:\n",
    "    class_name=class_dir.split(os.sep)[-1] #獲取當前類别\n",
    "    img_list=glob.glob(class_dir+os.sep+\"*\") #獲取每個類别文件夾下的所有圖片\n",
    "    all_num=len(img_list) #獲取總個數\n",
    "    train_list=random.sample(img_list,int(all_num*train_val_num)) #訓練集圖片所在路徑\n",
    "    save_one=save_dir+os.sep+os.sep+class_name\n",
    "    save_two=save_dir2+os.sep+os.sep+class_name\n",
    "    os.makedirs(save_one,exist_ok=True)\n",
    "    os.makedirs(save_two,exist_ok=True)\n",
    "\n",
    "\n",
    "    #保存切分好的數據集\n",
    "    for imgpath in img_list:\n",
    "        imgname=Path(imgpath).name #獲取文件名\n",
    "        if imgpath in train_list:\n",
    "            img=cv2.imread(imgpath)\n",
    "            new_img=expend_img(img)\n",
    "            cv2.imwrite(save_one+os.sep+imgname,new_img)\n",
    "        # else:\n",
    "        #     img=cv2.imread(imgpath)\n",
    "        #     new_img=expend_img(img)\n",
    "        #     cv2.imwrite(save_two+os.sep+imgname,new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將資料集切成train和val\n",
    "\n",
    "img_dir = 'cifar_10/register'\n",
    "save_dir = 'cifar_10/register_split' \n",
    "# img_dir = 'imagenette_10percent/second_5percent'\n",
    "# save_dir = 'imagenette_10percent/second_5percent_split' \n",
    "train_val_num = 0.7\n",
    "split_train_test(img_dir,save_dir,train_val_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#圖片資料增強\n",
    "\n",
    "img_dir = 'cifar_10\\cifar10_50percent_split/train'\n",
    "save_dir = 'cifar_10\\cifar10_50percent_split' \n",
    "train_val_num = 1.0\n",
    "data_enhancement(img_dir,save_dir,train_val_num)\n",
    "perspective_transform(img_dir,save_dir,train_val_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#訓練efficientionnet\n",
    "\n",
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "#参數設置\n",
    "def parse_opt():\n",
    "    parser=argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--weights\",type=str,default=\"./model/efficientnet-b5-b6417697.pth\",help='initial weights path')#預訓練模型路徑\n",
    "    parser.add_argument(\"--img-dir\",type=str,default=\"./cifar_100/cifar100_50percent_just_good_model\",help=\"train image path\") #數據集的路徑\n",
    "    parser.add_argument(\"--imgsz\",type=int,default=224,help=\"image size\") #圖像尺寸\n",
    "    parser.add_argument(\"--epochs\",type=int,default=50,help=\"train epochs\")#訓練批次\n",
    "    parser.add_argument(\"--batch-size\",type=int,default=8,help=\"train batch-size\") #batch-size\n",
    "    parser.add_argument(\"--class_num\",type=int,default=100,help=\"class num\") #類別數\n",
    "    parser.add_argument(\"--lr\",type=float,default=0.0005,help=\"Init lr\") #學習率初始值\n",
    "    parser.add_argument(\"--m\",type=float,default=0.9,help=\"optimer momentum\") #動量\n",
    "    parser.add_argument(\"--save-dir\",type=str,default=\"./weight\",help=\"save models dir\")#保存模型路徑\n",
    "\n",
    "    parser.add_argument(\"--save-model-name\",type=str,default=\"efficientb5_cifar100_50percent_just_good_model.pth\",help=\"save models name\")#保存模型路徑\n",
    "    \n",
    "    opt=parser.parse_known_args()[0]\n",
    "    return opt\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    opt=parse_opt()\n",
    "    models=Efficientnet_train(opt)\n",
    "    models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成dict，內容 : ( 各類的cofidence , gt label  ) \n",
    "\n",
    "tensor = []\n",
    "label = []\n",
    "class_num = []\n",
    "path = []\n",
    "\n",
    "input_size = 224\n",
    "device = 'cuda'\n",
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor\n",
    "means = [0.485, 0.456, 0.406]\n",
    "stds = [0.229, 0.224, 0.225]\n",
    "unorm = UnNormalize(mean = means, std = stds)\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    def __init__(self, *args):\n",
    "        super(ImageFolderWithPaths, self).__init__(*args)\n",
    "        self.trans = args[1]\n",
    "    def __len__(self):\n",
    "      return len(self.imgs)\n",
    "    def __getitem__(self, index):\n",
    "        img, label = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        \n",
    "        path = self.imgs[index][0]\n",
    "        return (img, label ,path)\n",
    "# Load Test images\n",
    "def loaddata(data_dir, batch_size, set_name, shuffle):\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(means, stds)\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(means, stds)\n",
    "        ]),\n",
    "        'test_class': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(means, stds)\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    image_datasets = {x: ImageFolderWithPaths(os.path.join(data_dir, x), data_transforms[x]) for x in [set_name]}\n",
    "    # num_workers=0 if CPU else = 1\n",
    "    dataset_loaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                                      batch_size=batch_size,\n",
    "                                                      shuffle=shuffle, num_workers=0) for x in [set_name]}\n",
    "    data_set_sizes = len(image_datasets[set_name])\n",
    "    return dataset_loaders, data_set_sizes\n",
    "\n",
    "\n",
    "def test_model(model, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    cont = 0\n",
    "    outPre = []\n",
    "    initi_tensor = []\n",
    "    outLabel = []\n",
    "    img_path = []\n",
    "    dset_loaders, dset_sizes = loaddata(data_dir=data_dir, batch_size=batch_size, set_name='train', shuffle=False)\n",
    "    transform = T.ToPILImage()\n",
    "    for data in dset_loaders['train']:\n",
    "        inputs, labels, paths = data #path抓出被分類的圖片的原始路徑\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        \n",
    "\n",
    "        # GPU\n",
    "        inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        tensor.append(outputs.data)\n",
    "\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "        class_num.append(labels)\n",
    "\n",
    "        path.append(paths)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        if cont == 0:\n",
    "            outPre = outputs.data.cpu()\n",
    "            outLabel = labels.data.cpu()\n",
    "        else:\n",
    "            outPre = torch.cat((outPre, outputs.data.cpu()), 0)\n",
    "            outLabel = torch.cat((outLabel, labels.data.cpu()), 0)\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        cont += len(labels)\n",
    "        acc = running_corrects/cont\n",
    "\n",
    "    return FUN.softmax(Variable(outPre)).data.numpy(), outLabel.numpy()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "    # Start Testing\n",
    "    net_name = 'efficientnet-b5'\n",
    "    data_dir = 'cifar_100/train_class'\n",
    "    save_dir = 'weight/0803'\n",
    "    modelft_file = save_dir + \"/\" + 'efficientb5_cifar100_100percent' + '.pth'\n",
    "    batch_size = 1\n",
    "\n",
    "    # GPU時\n",
    "    model_ft = efficientnet_pytorch.EfficientNet.from_name(net_name)\n",
    "    # 修改全連接層\n",
    "    num_ftrs = model_ft._fc.in_features\n",
    "    model_ft._fc = nn.Linear(num_ftrs, 100)\n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "    model_ft.load_state_dict(torch.load(modelft_file))\n",
    "    print(type(model_ft))\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "    outPre, outLabel = test_model(model_ft, criterion)\n",
    "\n",
    "\n",
    "print(str(len(tensor)),'----',str(len(class_num)),str(len(path)))\n",
    "\n",
    "with open('pickle/cifar100_100percent/cifar100_all_tensor.pickle', 'wb') as f:\n",
    "    pickle.dump(tensor, f)\n",
    "\n",
    "with open('pickle/cifar100_100percent/cifar100_all_class_label.pickle', 'wb') as f:\n",
    "    pickle.dump(class_num, f)\n",
    "\n",
    "with open('pickle/cifar100_100percent/cifar100_all_path.pickle', 'wb') as f:\n",
    "    pickle.dump(path, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成資料夾\n",
    "\n",
    "path = 'pickle/cifar100_test/class'\n",
    "for t in range(100):    \n",
    "    os.makedirs(path+str(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#製作label和資料集 ( 只取最大的值 )\n",
    "\n",
    "#分類標準 0:上升 1:不變 2:下降\n",
    "\n",
    "with open('pickle/cifar100_train_tensor.pickle', 'rb') as f:\n",
    "    train_tensor = pickle.load(f)\n",
    "with open('pickle/cifar100_train_label.pickle', 'rb') as f:\n",
    "    train_label = pickle.load(f)\n",
    "with open('pickle/cifar100_val_tensor.pickle', 'rb') as f:\n",
    "    val_tensor = pickle.load(f)\n",
    "with open('pickle/cifar100_val_label.pickle', 'rb') as f:\n",
    "    val_label = pickle.load(f)\n",
    "\n",
    "path = 'pickle/cifar100_test'\n",
    "class_num = 100\n",
    "for class_ in range(class_num):\n",
    "\n",
    "    t_label = []\n",
    "    t_data = []\n",
    "    v_label = []\n",
    "    v_data = []\n",
    "    count0 = 0\n",
    "    count1 = 0\n",
    "    count2 = 0\n",
    "    count3 = 0\n",
    "    count4 = 0\n",
    "    # os.makedirs(path+'/'+'class'+str(class_))\n",
    "\n",
    "    for t in range(len(train_tensor)):\n",
    "        value , index = torch.sort(train_tensor[t].squeeze(),descending = True)\n",
    "        # for t2 in range(int(len(index)/33)):\n",
    "        for t2 in range(int(len(index)/20)):\n",
    "\n",
    "            if int(index[t2]) == class_:\n",
    "                \n",
    "\n",
    "                # tensor = torch.empty(1,9)\n",
    "                # for t3 in range(9):\n",
    "                #     tensor[0][t3] = (train_tensor[t][0][index[t2]] - train_tensor[t][0][index[t2+t3+1]]) / train_tensor[t][0][index[t2]]\n",
    "                # t_data.append(tensor)\n",
    "\n",
    "                t_data.append(train_tensor[t])\n",
    "\n",
    "                differ = train_label[t][0][class_] - train_tensor[t][0][class_]\n",
    "                if differ >= 0:\n",
    "                    increase = abs(differ) / abs(train_tensor[t][0][class_])\n",
    "\n",
    "                    if increase > 1 :\n",
    "                        classifi = 0\n",
    "                        count0+=1\n",
    "\n",
    "                    elif increase<=1:\n",
    "                        classifi = 1\n",
    "                        count1+=1\n",
    "\n",
    "                else:\n",
    "                    reduce = abs(differ) / abs(train_tensor[t][0][class_])\n",
    "\n",
    "                    if reduce > 0.5 :\n",
    "                        classifi = 2\n",
    "                        count2+=1\n",
    "\n",
    "                    elif reduce<=0.5:\n",
    "                        classifi = 1\n",
    "                        count1+=1\n",
    "\n",
    "                t_label.append(torch.tensor(classifi))\n",
    "    \n",
    "    da = torch.stack(t_data)\n",
    "    la = torch.stack(t_label)\n",
    "    print(len(t_data),'---',len(t_label))\n",
    "    print(count0,'--',count1,'--',count2,'--',count3,'--',count4)\n",
    "    with open(path+'/'+'class'+str(class_)+'/cifar100_class'+str(class_)+'_label.pickle', 'wb') as f:\n",
    "        pickle.dump(la, f)\n",
    "    with open(path+'/'+'class'+str(class_)+'/cifar100_class'+str(class_)+'_tensor.pickle', 'wb') as f:\n",
    "        pickle.dump(da, f)\n",
    "\n",
    "\n",
    "    for t in range(len(val_tensor)):\n",
    "        value , index = torch.sort(val_tensor[t].squeeze(),descending = True)\n",
    "        # for t2 in range(int(len(index)/33)):\n",
    "        for t2 in range(int(len(index)/20)):\n",
    "\n",
    "            if int(index[t2]) == class_:\n",
    "\n",
    "\n",
    "                # tensor = torch.empty(1,9)\n",
    "                # for t3 in range(9):\n",
    "                #     tensor[0][t3] = (val_tensor[t][0][index[t2]] - val_tensor[t][0][index[t2+t3+1]]) / val_tensor[t][0][index[t2]]\n",
    "                # t_data.append(tensor)\n",
    "                # v_data.append(tensor)\n",
    "\n",
    "                v_data.append(val_tensor[t])\n",
    "\n",
    "                differ = val_label[t][0][class_] - val_tensor[t][0][class_]\n",
    "                if differ >= 0:\n",
    "                    increase = abs(differ) / abs(val_tensor[t][0][class_])\n",
    "\n",
    "                    if increase > 1 :\n",
    "                        classifi = 0\n",
    "                        count0+=1\n",
    "\n",
    "                    elif increase<=1:\n",
    "                        classifi = 1\n",
    "                        count1+=1\n",
    "\n",
    "                else:\n",
    "                    reduce = abs(differ) / abs(val_tensor[t][0][class_])\n",
    "\n",
    "                    if reduce > 0.5 :\n",
    "                        classifi = 2\n",
    "                        count2+=1\n",
    "\n",
    "                    elif reduce<=0.5:\n",
    "                        classifi = 1\n",
    "                        count1+=1\n",
    "\n",
    "                v_label.append(torch.tensor(classifi))\n",
    "    \n",
    "    da2 = torch.stack(v_data)\n",
    "    la2 = torch.stack(v_label)\n",
    "    print(len(v_data),'---',len(v_label))\n",
    "    print(count0,'--',count1,'--',count2,'--',count3,'--',count4)\n",
    "    with open(path+'/'+'class'+str(class_)+'/cifar100_val_class'+str(class_)+'_label.pickle', 'wb') as f:\n",
    "        pickle.dump(la2, f)\n",
    "    with open(path+'/'+'class'+str(class_)+'/cifar100_val_class'+str(class_)+'_tensor.pickle', 'wb') as f:\n",
    "        pickle.dump(da2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init success !!\n"
     ]
    }
   ],
   "source": [
    "#定義分類模型\n",
    "\n",
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MyResModel = LSTM_FCN(input_dim=1, hidden_dim=32, output_dim=3, layers=1).to(device)\n",
    "MyResModel.init_model()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(MyResModel.parameters(), lr=0.001, momentum=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 學習率慢热加下降\n",
    "def lrfn(num_epoch, optimzer):\n",
    "    lr_start = 0.001  # 初始值\n",
    "    max_lr = 0.005  # 最大值\n",
    "    lr_up_epoch =150  # 學習率上升10个epoch\n",
    "    lr_sustain_epoch = 50  # 學習率保持不變\n",
    "    lr_exp = .8  # 衰减因子\n",
    "    if num_epoch < lr_up_epoch:  # 0-10个epoch學習率線性增加\n",
    "        lr = (max_lr - lr_start) / lr_up_epoch * num_epoch + lr_start\n",
    "    elif num_epoch < lr_up_epoch + lr_sustain_epoch:  # 學習率保持不變\n",
    "        lr = max_lr\n",
    "    else:  # 指數下降\n",
    "        lr = (max_lr - lr_start) * lr_exp ** (num_epoch - lr_up_epoch - lr_sustain_epoch) + lr_start\n",
    "    for param_group in optimzer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    return optimzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Taka\\anaconda3\\envs\\taka1\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "c:\\Users\\Taka\\anaconda3\\envs\\taka1\\lib\\site-packages\\ipykernel_launcher.py:98: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 100.0 loss : 0.7075719331440172 Acc : 0.84375\n",
      "class 1 model\n",
      "epoch : 100.0 loss : 0.9098750352859497 Acc : 0.625\n",
      "epoch : 300.0 loss : 0.8637825151284536 Acc : 0.6875\n",
      "epoch : 600.0 loss : 0.8681372702121735 Acc : 0.6875\n",
      "epoch : 700.0 loss : 0.8637609283129374 Acc : 0.6875\n",
      "class 2 model\n",
      "epoch : 100.0 loss : 0.9228382110595703 Acc : 0.6276041666666666\n",
      "epoch : 200.0 loss : 0.8903159896532694 Acc : 0.6614583333333334\n",
      "epoch : 400.0 loss : 0.8794773519039154 Acc : 0.6692708333333334\n",
      "epoch : 600.0 loss : 0.8395985017220179 Acc : 0.7109375\n",
      "class 3 model\n",
      "epoch : 100.0 loss : 1.0627556890249252 Acc : 0.48828125\n",
      "epoch : 200.0 loss : 1.030042752623558 Acc : 0.51953125\n",
      "epoch : 300.0 loss : 0.7577744722366333 Acc : 0.79296875\n",
      "epoch : 400.0 loss : 0.7453185543417931 Acc : 0.8046875\n",
      "epoch : 800.0 loss : 0.7437660321593285 Acc : 0.80859375\n",
      "class 4 model\n",
      "epoch : 100.0 loss : 1.0194397270679474 Acc : 0.53125\n",
      "epoch : 200.0 loss : 1.0117085576057434 Acc : 0.5390625\n",
      "class 5 model\n",
      "epoch : 100.0 loss : 1.0253473867972691 Acc : 0.5260416666666666\n",
      "epoch : 200.0 loss : 1.0225199063618977 Acc : 0.5260416666666666\n",
      "epoch : 300.0 loss : 1.0055400530497234 Acc : 0.5416666666666666\n",
      "epoch : 500.0 loss : 0.9967922617991766 Acc : 0.5520833333333334\n",
      "epoch : 700.0 loss : 0.9597532004117966 Acc : 0.59375\n",
      "epoch : 800.0 loss : 0.9564997355143229 Acc : 0.59375\n",
      "class 6 model\n",
      "epoch : 100.0 loss : 0.9832832387515477 Acc : 0.5669642857142857\n",
      "epoch : 200.0 loss : 0.9246984039034162 Acc : 0.625\n",
      "epoch : 300.0 loss : 0.9263693605150495 Acc : 0.625\n",
      "class 7 model\n",
      "epoch : 100.0 loss : 0.9106228291988373 Acc : 0.640625\n",
      "epoch : 200.0 loss : 0.9015144228935241 Acc : 0.65\n",
      "epoch : 300.0 loss : 0.898767751455307 Acc : 0.65\n",
      "epoch : 400.0 loss : 0.894754844903946 Acc : 0.653125\n",
      "epoch : 500.0 loss : 0.8940286278724671 Acc : 0.653125\n",
      "epoch : 600.0 loss : 0.8928520739078522 Acc : 0.653125\n",
      "epoch : 700.0 loss : 0.8860828280448914 Acc : 0.665625\n",
      "class 8 model\n",
      "epoch : 100.0 loss : 0.9144983887672424 Acc : 0.6375\n",
      "epoch : 300.0 loss : 0.8990702092647552 Acc : 0.646875\n",
      "epoch : 400.0 loss : 0.8980090200901032 Acc : 0.65\n",
      "epoch : 600.0 loss : 0.9018498241901398 Acc : 0.65\n",
      "class 9 model\n",
      "epoch : 100.0 loss : 1.016845079985532 Acc : 0.53125\n",
      "epoch : 200.0 loss : 0.9539342793551359 Acc : 0.5994318181818182\n",
      "epoch : 300.0 loss : 0.9434378472241488 Acc : 0.6079545454545454\n",
      "epoch : 500.0 loss : 0.9234137806025419 Acc : 0.6278409090909091\n",
      "epoch : 600.0 loss : 0.9209200685674493 Acc : 0.6306818181818182\n",
      "class 10 model\n",
      "epoch : 100.0 loss : 0.8793704130432822 Acc : 0.6704545454545454\n",
      "epoch : 200.0 loss : 0.8639868931336836 Acc : 0.6846590909090909\n",
      "epoch : 400.0 loss : 0.8556199398907748 Acc : 0.6931818181818182\n",
      "epoch : 500.0 loss : 0.853203605521809 Acc : 0.6988636363636364\n",
      "epoch : 600.0 loss : 0.8402587175369263 Acc : 0.7102272727272727\n",
      "epoch : 800.0 loss : 0.8339339223774996 Acc : 0.7159090909090909\n",
      "class 11 model\n",
      "epoch : 100.0 loss : 0.9419869258999825 Acc : 0.609375\n",
      "epoch : 200.0 loss : 0.9430915117263794 Acc : 0.609375\n",
      "epoch : 400.0 loss : 0.9292012304067612 Acc : 0.62109375\n",
      "epoch : 600.0 loss : 0.9152963384985924 Acc : 0.63671875\n",
      "class 12 model\n",
      "epoch : 100.0 loss : 0.7372519705030653 Acc : 0.8125\n",
      "epoch : 200.0 loss : 0.7248318062888252 Acc : 0.8263888888888888\n",
      "epoch : 300.0 loss : 0.7191802594396803 Acc : 0.8333333333333334\n",
      "class 13 model\n",
      "epoch : 100.0 loss : 0.8986039519309997 Acc : 0.6520833333333333\n",
      "epoch : 200.0 loss : 0.8832858522733052 Acc : 0.66875\n",
      "class 14 model\n",
      "epoch : 100.0 loss : 0.8476937275666457 Acc : 0.7019230769230769\n",
      "epoch : 200.0 loss : 0.8416127837621249 Acc : 0.7091346153846154\n",
      "class 15 model\n",
      "epoch : 100.0 loss : 0.7750652049268995 Acc : 0.7700892857142857\n",
      "epoch : 200.0 loss : 0.7752447298594883 Acc : 0.7700892857142857\n",
      "epoch : 300.0 loss : 0.77105170914105 Acc : 0.7790178571428571\n",
      "epoch : 400.0 loss : 0.7677287587097713 Acc : 0.7790178571428571\n",
      "epoch : 500.0 loss : 0.7639624731881278 Acc : 0.7857142857142857\n",
      "epoch : 600.0 loss : 0.7522730869906289 Acc : 0.8013392857142857\n",
      "class 16 model\n",
      "epoch : 100.0 loss : 0.746627316830006 Acc : 0.8048537234042553\n",
      "class 17 model\n",
      "epoch : 100.0 loss : 0.7694400681389703 Acc : 0.78125\n",
      "epoch : 200.0 loss : 0.7667734656069014 Acc : 0.7847222222222222\n",
      "epoch : 300.0 loss : 0.7667685151100159 Acc : 0.7847222222222222\n",
      "epoch : 400.0 loss : 0.7667579783333672 Acc : 0.7847222222222222\n",
      "class 18 model\n",
      "epoch : 100.0 loss : 1.1167005747556686 Acc : 0.43359375\n",
      "epoch : 200.0 loss : 1.010473646223545 Acc : 0.5390625\n",
      "epoch : 500.0 loss : 1.009672224521637 Acc : 0.54296875\n",
      "epoch : 800.0 loss : 1.000026561319828 Acc : 0.55078125\n",
      "class 19 model\n",
      "epoch : 100.0 loss : 0.9222134113311767 Acc : 0.625\n",
      "epoch : 200.0 loss : 0.9235669732093811 Acc : 0.625\n",
      "class 20 model\n",
      "epoch : 100.0 loss : 1.1295692399144173 Acc : 0.421875\n",
      "class 21 model\n",
      "epoch : 100.0 loss : 0.9262750479910109 Acc : 0.625\n",
      "epoch : 200.0 loss : 0.8944696585337321 Acc : 0.65625\n",
      "epoch : 300.0 loss : 0.8957398798730638 Acc : 0.65625\n",
      "class 22 model\n",
      "epoch : 100.0 loss : 1.002651534974575 Acc : 0.546875\n",
      "epoch : 200.0 loss : 0.9155738055706024 Acc : 0.63671875\n",
      "class 23 model\n",
      "epoch : 100.0 loss : 0.8604237024600689 Acc : 0.6899038461538461\n",
      "epoch : 300.0 loss : 0.8440000919195322 Acc : 0.7067307692307693\n",
      "class 24 model\n",
      "epoch : 100.0 loss : 0.7715365575707477 Acc : 0.779891304347826\n",
      "epoch : 200.0 loss : 0.7689199732697528 Acc : 0.782608695652174\n",
      "epoch : 400.0 loss : 0.7677528080732926 Acc : 0.782608695652174\n",
      "epoch : 800.0 loss : 0.7688903730848561 Acc : 0.782608695652174\n",
      "class 25 model\n",
      "epoch : 100.0 loss : 0.9211108287175497 Acc : 0.6302083333333334\n",
      "epoch : 200.0 loss : 0.9182060261567434 Acc : 0.6328125\n",
      "epoch : 700.0 loss : 0.9158266137043635 Acc : 0.6354166666666666\n",
      "class 26 model\n",
      "epoch : 100.0 loss : 0.0 Acc : 0.0\n",
      "epoch : 200.0 loss : 0.0 Acc : 0.0\n",
      "epoch : 300.0 loss : 0.0 Acc : 0.0\n",
      "epoch : 400.0 loss : 0.0 Acc : 0.0\n",
      "epoch : 500.0 loss : 0.0 Acc : 0.0\n",
      "epoch : 600.0 loss : 0.0 Acc : 0.0\n",
      "epoch : 700.0 loss : 0.0 Acc : 0.0\n",
      "epoch : 800.0 loss : 0.0 Acc : 0.0\n",
      "class 27 model\n",
      "epoch : 100.0 loss : 0.8732035137988903 Acc : 0.6782407407407407\n",
      "epoch : 200.0 loss : 0.87320418048788 Acc : 0.6782407407407407\n",
      "epoch : 300.0 loss : 0.8732038758419178 Acc : 0.6782407407407407\n",
      "epoch : 400.0 loss : 0.8732361837669655 Acc : 0.6782407407407407\n",
      "epoch : 500.0 loss : 0.8728794499679848 Acc : 0.6782407407407407\n",
      "epoch : 600.0 loss : 0.8720394328788474 Acc : 0.6793981481481481\n",
      "epoch : 800.0 loss : 0.870879038616463 Acc : 0.6805555555555556\n",
      "class 28 model\n",
      "epoch : 100.0 loss : 0.9359905570745468 Acc : 0.6145833333333334\n",
      "epoch : 200.0 loss : 0.8902413249015808 Acc : 0.6614583333333334\n",
      "class 29 model\n",
      "epoch : 100.0 loss : 0.7465447733799616 Acc : 0.8046875\n",
      "epoch : 200.0 loss : 0.7425185839335123 Acc : 0.8098958333333334\n",
      "epoch : 400.0 loss : 0.736368531982104 Acc : 0.8151041666666666\n",
      "class 30 model\n",
      "epoch : 100.0 loss : 0.8742376863956451 Acc : 0.6770833333333334\n",
      "epoch : 300.0 loss : 0.8754099309444427 Acc : 0.6770833333333334\n",
      "epoch : 400.0 loss : 0.8732122282187144 Acc : 0.6796875\n",
      "class 31 model\n",
      "epoch : 100.0 loss : 1.0536961058775585 Acc : 0.4947916666666667\n",
      "epoch : 200.0 loss : 1.0410282611846924 Acc : 0.5104166666666666\n",
      "epoch : 300.0 loss : 1.0410282611846924 Acc : 0.5104166666666666\n",
      "epoch : 400.0 loss : 1.0410282611846924 Acc : 0.5104166666666666\n",
      "epoch : 500.0 loss : 1.0410282611846924 Acc : 0.5104166666666666\n",
      "epoch : 600.0 loss : 1.0410282611846924 Acc : 0.5104166666666666\n",
      "epoch : 700.0 loss : 1.0410282611846924 Acc : 0.5104166666666666\n",
      "epoch : 800.0 loss : 1.0410282611846924 Acc : 0.5104166666666666\n",
      "class 32 model\n",
      "epoch : 100.0 loss : 0.878523059686025 Acc : 0.6729166666666667\n",
      "epoch : 200.0 loss : 0.8533808867136637 Acc : 0.6979166666666666\n",
      "epoch : 700.0 loss : 0.8535930395126343 Acc : 0.6979166666666666\n",
      "class 33 model\n",
      "epoch : 100.0 loss : 0.8889443457126618 Acc : 0.6625\n",
      "epoch : 200.0 loss : 0.8889391362667084 Acc : 0.6625\n",
      "epoch : 300.0 loss : 0.8889382243156433 Acc : 0.6625\n",
      "epoch : 400.0 loss : 0.8889409482479096 Acc : 0.6625\n",
      "epoch : 500.0 loss : 0.8889316439628601 Acc : 0.6625\n",
      "epoch : 600.0 loss : 0.8889444470405579 Acc : 0.6625\n",
      "epoch : 700.0 loss : 0.8889448761940002 Acc : 0.6625\n",
      "epoch : 800.0 loss : 0.8889448702335357 Acc : 0.6625\n",
      "class 34 model\n",
      "epoch : 100.0 loss : 0.8389447251955668 Acc : 0.7125\n",
      "epoch : 200.0 loss : 0.8377493500709534 Acc : 0.7125\n",
      "epoch : 300.0 loss : 0.8349681218465169 Acc : 0.7166666666666667\n",
      "epoch : 400.0 loss : 0.835074520111084 Acc : 0.7166666666666667\n",
      "class 35 model\n",
      "epoch : 100.0 loss : 1.067069910466671 Acc : 0.484375\n",
      "epoch : 300.0 loss : 1.0538985654711723 Acc : 0.49609375\n",
      "epoch : 700.0 loss : 0.9648081585764885 Acc : 0.5859375\n",
      "class 36 model\n",
      "epoch : 100.0 loss : 0.8435790306992001 Acc : 0.7083333333333334\n",
      "class 37 model\n",
      "epoch : 100.0 loss : 0.8991901092231274 Acc : 0.65234375\n",
      "epoch : 200.0 loss : 0.8627943731844425 Acc : 0.689453125\n",
      "class 38 model\n",
      "epoch : 100.0 loss : 0.7480303466320037 Acc : 0.803125\n",
      "epoch : 200.0 loss : 0.745194947719574 Acc : 0.80625\n",
      "epoch : 300.0 loss : 0.7451951682567597 Acc : 0.80625\n",
      "class 39 model\n",
      "epoch : 100.0 loss : 0.992417143450843 Acc : 0.5590277777777778\n",
      "epoch : 200.0 loss : 0.9924171500735812 Acc : 0.5590277777777778\n",
      "epoch : 300.0 loss : 0.992417143450843 Acc : 0.5590277777777778\n",
      "epoch : 400.0 loss : 0.992417143450843 Acc : 0.5590277777777778\n",
      "epoch : 500.0 loss : 0.992417143450843 Acc : 0.5590277777777778\n",
      "epoch : 600.0 loss : 0.992417143450843 Acc : 0.5590277777777778\n",
      "epoch : 700.0 loss : 0.9923048085636563 Acc : 0.5590277777777778\n",
      "epoch : 800.0 loss : 0.9922095073593987 Acc : 0.5590277777777778\n",
      "class 40 model\n",
      "epoch : 100.0 loss : 0.863944947719574 Acc : 0.6875\n",
      "epoch : 200.0 loss : 0.8604727254973518 Acc : 0.6909722222222222\n",
      "epoch : 300.0 loss : 0.8604727254973518 Acc : 0.6909722222222222\n",
      "epoch : 400.0 loss : 0.8604727254973518 Acc : 0.6909722222222222\n",
      "epoch : 500.0 loss : 0.8604727254973518 Acc : 0.6909722222222222\n",
      "epoch : 600.0 loss : 0.8604727254973518 Acc : 0.6909722222222222\n",
      "epoch : 700.0 loss : 0.8604727254973518 Acc : 0.6909722222222222\n",
      "epoch : 800.0 loss : 0.8604727254973518 Acc : 0.6909722222222222\n",
      "class 41 model\n",
      "epoch : 100.0 loss : 1.349736061963168 Acc : 0.20170454545454544\n",
      "epoch : 200.0 loss : 1.3497421849857678 Acc : 0.20170454545454544\n",
      "epoch : 300.0 loss : 1.3497418815439397 Acc : 0.20170454545454544\n",
      "epoch : 400.0 loss : 1.349710551175204 Acc : 0.20170454545454544\n",
      "epoch : 500.0 loss : 1.349710551175204 Acc : 0.20170454545454544\n",
      "epoch : 600.0 loss : 1.349710551175204 Acc : 0.20170454545454544\n",
      "epoch : 700.0 loss : 1.349710551175204 Acc : 0.20170454545454544\n",
      "epoch : 800.0 loss : 1.349710551175204 Acc : 0.20170454545454544\n",
      "class 42 model\n",
      "epoch : 100.0 loss : 1.0442333840406859 Acc : 0.5072115384615384\n",
      "class 43 model\n",
      "epoch : 100.0 loss : 0.8460878006049565 Acc : 0.7053571428571429\n",
      "epoch : 200.0 loss : 0.8460878006049565 Acc : 0.7053571428571429\n",
      "epoch : 300.0 loss : 0.8460878006049565 Acc : 0.7053571428571429\n",
      "epoch : 400.0 loss : 0.8460878006049565 Acc : 0.7053571428571429\n",
      "epoch : 500.0 loss : 0.8460878006049565 Acc : 0.7053571428571429\n",
      "epoch : 600.0 loss : 0.8460878006049565 Acc : 0.7053571428571429\n",
      "epoch : 700.0 loss : 0.8460878006049565 Acc : 0.7053571428571429\n",
      "epoch : 800.0 loss : 0.8460878006049565 Acc : 0.7053571428571429\n",
      "class 44 model\n",
      "epoch : 100.0 loss : 0.748766371182033 Acc : 0.8026785714285715\n",
      "epoch : 200.0 loss : 0.748766371182033 Acc : 0.8026785714285715\n",
      "epoch : 300.0 loss : 0.748766371182033 Acc : 0.8026785714285715\n",
      "epoch : 400.0 loss : 0.748766371182033 Acc : 0.8026785714285715\n",
      "epoch : 500.0 loss : 0.748766371182033 Acc : 0.8026785714285715\n",
      "epoch : 600.0 loss : 0.748766371182033 Acc : 0.8026785714285715\n",
      "epoch : 700.0 loss : 0.748766371182033 Acc : 0.8026785714285715\n",
      "epoch : 800.0 loss : 0.748766371182033 Acc : 0.8026785714285715\n",
      "class 45 model\n",
      "epoch : 100.0 loss : 1.0592574179172516 Acc : 0.4921875\n",
      "epoch : 200.0 loss : 1.0592574179172516 Acc : 0.4921875\n",
      "epoch : 300.0 loss : 1.0592574179172516 Acc : 0.4921875\n",
      "epoch : 400.0 loss : 1.0592574179172516 Acc : 0.4921875\n",
      "epoch : 500.0 loss : 1.0592574179172516 Acc : 0.4921875\n",
      "epoch : 600.0 loss : 1.0592574179172516 Acc : 0.4921875\n",
      "epoch : 700.0 loss : 1.0592574179172516 Acc : 0.4921875\n",
      "epoch : 800.0 loss : 1.0592574179172516 Acc : 0.4921875\n",
      "class 46 model\n",
      "epoch : 100.0 loss : 1.0960877537727356 Acc : 0.45535714285714285\n",
      "epoch : 200.0 loss : 1.0960877537727356 Acc : 0.45535714285714285\n",
      "epoch : 300.0 loss : 1.0960877537727356 Acc : 0.45535714285714285\n",
      "epoch : 400.0 loss : 1.0960877537727356 Acc : 0.45535714285714285\n",
      "epoch : 500.0 loss : 1.0960877537727356 Acc : 0.45535714285714285\n",
      "epoch : 600.0 loss : 1.0960877537727356 Acc : 0.45535714285714285\n",
      "epoch : 700.0 loss : 1.0960877537727356 Acc : 0.45535714285714285\n",
      "epoch : 800.0 loss : 1.0960877537727356 Acc : 0.45535714285714285\n",
      "class 47 model\n",
      "epoch : 100.0 loss : 1.0097782512505848 Acc : 0.5416666666666666\n",
      "epoch : 200.0 loss : 1.0097782512505848 Acc : 0.5416666666666666\n",
      "epoch : 300.0 loss : 1.0097782512505848 Acc : 0.5416666666666666\n",
      "epoch : 400.0 loss : 1.0097782512505848 Acc : 0.5416666666666666\n",
      "epoch : 500.0 loss : 1.0097782512505848 Acc : 0.5416666666666666\n",
      "epoch : 600.0 loss : 1.0097782512505848 Acc : 0.5416666666666666\n",
      "epoch : 700.0 loss : 1.0097782512505848 Acc : 0.5416666666666666\n",
      "epoch : 800.0 loss : 1.0097782512505848 Acc : 0.5416666666666666\n",
      "class 48 model\n",
      "epoch : 100.0 loss : 1.0259514984331632 Acc : 0.5254934210526315\n",
      "epoch : 200.0 loss : 1.0259514984331632 Acc : 0.5254934210526315\n",
      "epoch : 300.0 loss : 1.0259514984331632 Acc : 0.5254934210526315\n",
      "epoch : 400.0 loss : 1.0259514984331632 Acc : 0.5254934210526315\n",
      "epoch : 500.0 loss : 1.0259514984331632 Acc : 0.5254934210526315\n",
      "epoch : 600.0 loss : 1.0259514984331632 Acc : 0.5254934210526315\n",
      "epoch : 700.0 loss : 1.0259514984331632 Acc : 0.5254934210526315\n",
      "epoch : 800.0 loss : 1.0259514984331632 Acc : 0.5254934210526315\n",
      "class 49 model\n",
      "epoch : 100.0 loss : 0.6600759001005263 Acc : 0.8913690476190477\n",
      "epoch : 200.0 loss : 0.6600759001005263 Acc : 0.8913690476190477\n",
      "epoch : 300.0 loss : 0.6600759001005263 Acc : 0.8913690476190477\n",
      "epoch : 400.0 loss : 0.6600759001005263 Acc : 0.8913690476190477\n",
      "epoch : 500.0 loss : 0.6600759001005263 Acc : 0.8913690476190477\n",
      "epoch : 600.0 loss : 0.6600759001005263 Acc : 0.8913690476190477\n",
      "epoch : 700.0 loss : 0.6600759001005263 Acc : 0.8913690476190477\n",
      "epoch : 800.0 loss : 0.6600759001005263 Acc : 0.8913690476190477\n",
      "class 50 model\n",
      "epoch : 100.0 loss : 0.7612663762910026 Acc : 0.7901785714285714\n",
      "epoch : 200.0 loss : 0.7612663762910026 Acc : 0.7901785714285714\n",
      "epoch : 300.0 loss : 0.7612663762910026 Acc : 0.7901785714285714\n",
      "epoch : 400.0 loss : 0.7612663762910026 Acc : 0.7901785714285714\n",
      "epoch : 500.0 loss : 0.7612663762910026 Acc : 0.7901785714285714\n",
      "epoch : 600.0 loss : 0.7612663762910026 Acc : 0.7901785714285714\n",
      "epoch : 700.0 loss : 0.7612663762910026 Acc : 0.7901785714285714\n",
      "epoch : 800.0 loss : 0.7612663762910026 Acc : 0.7901785714285714\n",
      "class 51 model\n",
      "epoch : 100.0 loss : 0.8781494823369113 Acc : 0.6732954545454546\n",
      "epoch : 200.0 loss : 0.8781494823369113 Acc : 0.6732954545454546\n",
      "epoch : 300.0 loss : 0.8781494823369113 Acc : 0.6732954545454546\n",
      "epoch : 400.0 loss : 0.8781494823369113 Acc : 0.6732954545454546\n",
      "epoch : 500.0 loss : 0.8781494823369113 Acc : 0.6732954545454546\n",
      "epoch : 600.0 loss : 0.8781494823369113 Acc : 0.6732954545454546\n",
      "epoch : 700.0 loss : 0.8781494823369113 Acc : 0.6732954545454546\n",
      "epoch : 800.0 loss : 0.8781494823369113 Acc : 0.6732954545454546\n",
      "class 52 model\n",
      "epoch : 100.0 loss : 1.0201949156247652 Acc : 0.53125\n",
      "epoch : 200.0 loss : 1.0201949156247652 Acc : 0.53125\n",
      "epoch : 300.0 loss : 1.0201949156247652 Acc : 0.53125\n",
      "epoch : 500.0 loss : 1.0147429888065045 Acc : 0.5360576923076923\n",
      "epoch : 600.0 loss : 0.9878154993057251 Acc : 0.5625\n",
      "epoch : 800.0 loss : 0.9809365134972793 Acc : 0.5697115384615384\n",
      "class 53 model\n",
      "epoch : 100.0 loss : 0.7344721811158317 Acc : 0.8169642857142857\n",
      "class 54 model\n",
      "epoch : 100.0 loss : 0.8639508895576 Acc : 0.6875\n",
      "epoch : 400.0 loss : 0.8561571426689625 Acc : 0.6953125\n",
      "epoch : 500.0 loss : 0.8560624867677689 Acc : 0.6953125\n",
      "epoch : 600.0 loss : 0.8544304333627224 Acc : 0.697265625\n",
      "class 55 model\n",
      "epoch : 100.0 loss : 0.989469462633133 Acc : 0.5614583333333333\n",
      "class 56 model\n",
      "epoch : 100.0 loss : 0.9006053642793135 Acc : 0.6505681818181818\n",
      "epoch : 200.0 loss : 0.89891502532092 Acc : 0.6534090909090909\n",
      "epoch : 500.0 loss : 0.8981393738226457 Acc : 0.6534090909090909\n",
      "epoch : 700.0 loss : 0.8935225226662376 Acc : 0.65625\n",
      "epoch : 800.0 loss : 0.8949913924390619 Acc : 0.65625\n",
      "class 57 model\n",
      "epoch : 100.0 loss : 0.7235847529718431 Acc : 0.8278601694915254\n",
      "class 58 model\n",
      "epoch : 100.0 loss : 0.715507447719574 Acc : 0.8359375\n",
      "epoch : 200.0 loss : 0.7155098229646683 Acc : 0.8359375\n",
      "epoch : 300.0 loss : 0.7155077636241913 Acc : 0.8359375\n",
      "epoch : 400.0 loss : 0.7155203729867935 Acc : 0.8359375\n",
      "epoch : 500.0 loss : 0.7156188994646072 Acc : 0.8359375\n",
      "epoch : 600.0 loss : 0.7155371248722077 Acc : 0.8359375\n",
      "epoch : 700.0 loss : 0.71553715467453 Acc : 0.8359375\n",
      "epoch : 800.0 loss : 0.7155416309833527 Acc : 0.8359375\n",
      "class 59 model\n",
      "epoch : 100.0 loss : 0.6655073821544647 Acc : 0.8859375\n",
      "epoch : 200.0 loss : 0.6655073821544647 Acc : 0.8859375\n",
      "epoch : 300.0 loss : 0.6655073821544647 Acc : 0.8859375\n",
      "epoch : 400.0 loss : 0.6655073761940002 Acc : 0.8859375\n",
      "epoch : 500.0 loss : 0.6639449715614318 Acc : 0.8875\n",
      "epoch : 600.0 loss : 0.6639449715614318 Acc : 0.8875\n",
      "epoch : 700.0 loss : 0.6639449715614318 Acc : 0.8875\n",
      "epoch : 800.0 loss : 0.6639449745416641 Acc : 0.8875\n",
      "class 60 model\n",
      "epoch : 100.0 loss : 1.059257410466671 Acc : 0.4921875\n",
      "epoch : 200.0 loss : 1.059257410466671 Acc : 0.4921875\n",
      "epoch : 300.0 loss : 1.059257410466671 Acc : 0.4921875\n",
      "epoch : 400.0 loss : 1.059257410466671 Acc : 0.4921875\n",
      "epoch : 500.0 loss : 1.059257410466671 Acc : 0.4921875\n",
      "epoch : 600.0 loss : 1.059257410466671 Acc : 0.4921875\n",
      "epoch : 700.0 loss : 1.059257410466671 Acc : 0.4921875\n",
      "epoch : 800.0 loss : 1.059257410466671 Acc : 0.4921875\n",
      "class 61 model\n",
      "epoch : 100.0 loss : 0.8325637524778192 Acc : 0.71875\n",
      "epoch : 300.0 loss : 0.8326026363806291 Acc : 0.71875\n",
      "epoch : 400.0 loss : 0.8326945250684564 Acc : 0.71875\n",
      "epoch : 500.0 loss : 0.8327187624844637 Acc : 0.71875\n",
      "epoch : 600.0 loss : 0.8329225019975142 Acc : 0.71875\n",
      "epoch : 700.0 loss : 0.8333312381397594 Acc : 0.71875\n",
      "class 62 model\n",
      "epoch : 100.0 loss : 0.9844806449753898 Acc : 0.5669642857142857\n",
      "epoch : 200.0 loss : 0.9844806449753898 Acc : 0.5669642857142857\n",
      "epoch : 300.0 loss : 0.9844806449753898 Acc : 0.5669642857142857\n",
      "epoch : 400.0 loss : 0.9844806449753898 Acc : 0.5669642857142857\n",
      "epoch : 500.0 loss : 0.9844806449753898 Acc : 0.5669642857142857\n",
      "epoch : 600.0 loss : 0.9844806449753898 Acc : 0.5669642857142857\n",
      "epoch : 700.0 loss : 0.9844806449753898 Acc : 0.5669642857142857\n",
      "epoch : 800.0 loss : 0.9844806449753898 Acc : 0.5669642857142857\n",
      "class 63 model\n",
      "epoch : 100.0 loss : 0.9030074328184128 Acc : 0.6484375\n",
      "epoch : 200.0 loss : 0.9030074328184128 Acc : 0.6484375\n",
      "epoch : 300.0 loss : 0.9030074328184128 Acc : 0.6484375\n",
      "epoch : 400.0 loss : 0.9030074328184128 Acc : 0.6484375\n",
      "epoch : 500.0 loss : 0.9030074328184128 Acc : 0.6484375\n",
      "epoch : 600.0 loss : 0.9030074328184128 Acc : 0.6484375\n",
      "epoch : 700.0 loss : 0.9030074328184128 Acc : 0.6484375\n",
      "epoch : 800.0 loss : 0.9030074328184128 Acc : 0.6484375\n",
      "class 64 model\n",
      "epoch : 100.0 loss : 1.082694910466671 Acc : 0.46875\n",
      "epoch : 200.0 loss : 1.082694910466671 Acc : 0.46875\n",
      "epoch : 300.0 loss : 1.082694910466671 Acc : 0.46875\n",
      "epoch : 400.0 loss : 1.082694910466671 Acc : 0.46875\n",
      "epoch : 500.0 loss : 1.082694910466671 Acc : 0.46875\n",
      "epoch : 600.0 loss : 1.082694910466671 Acc : 0.46875\n",
      "epoch : 700.0 loss : 1.082694910466671 Acc : 0.46875\n",
      "epoch : 800.0 loss : 1.082694910466671 Acc : 0.46875\n",
      "class 65 model\n",
      "epoch : 100.0 loss : 0.8757983857187731 Acc : 0.6756465517241379\n",
      "epoch : 200.0 loss : 0.8757983857187731 Acc : 0.6756465517241379\n",
      "epoch : 300.0 loss : 0.8757983857187731 Acc : 0.6756465517241379\n",
      "epoch : 400.0 loss : 0.8757983857187731 Acc : 0.6756465517241379\n",
      "epoch : 500.0 loss : 0.8757983857187731 Acc : 0.6756465517241379\n",
      "epoch : 600.0 loss : 0.8757983857187731 Acc : 0.6756465517241379\n",
      "epoch : 700.0 loss : 0.8757983857187731 Acc : 0.6756465517241379\n",
      "epoch : 800.0 loss : 0.8757983857187731 Acc : 0.6756465517241379\n",
      "class 66 model\n",
      "epoch : 100.0 loss : 0.9381636865437031 Acc : 0.61328125\n",
      "epoch : 200.0 loss : 0.9381636865437031 Acc : 0.61328125\n",
      "epoch : 300.0 loss : 0.9381636865437031 Acc : 0.61328125\n",
      "epoch : 400.0 loss : 0.9381636865437031 Acc : 0.61328125\n",
      "epoch : 500.0 loss : 0.9381636865437031 Acc : 0.61328125\n",
      "epoch : 600.0 loss : 0.9381636865437031 Acc : 0.61328125\n",
      "epoch : 700.0 loss : 0.9381636865437031 Acc : 0.61328125\n",
      "epoch : 800.0 loss : 0.9381636865437031 Acc : 0.61328125\n",
      "class 67 model\n",
      "epoch : 100.0 loss : 0.9168295447642987 Acc : 0.6346153846153846\n",
      "epoch : 200.0 loss : 0.9168295447642987 Acc : 0.6346153846153846\n",
      "epoch : 300.0 loss : 0.9168295447642987 Acc : 0.6346153846153846\n",
      "epoch : 400.0 loss : 0.9168295447642987 Acc : 0.6346153846153846\n",
      "epoch : 500.0 loss : 0.9168295447642987 Acc : 0.6346153846153846\n",
      "epoch : 600.0 loss : 0.9168295447642987 Acc : 0.6346153846153846\n",
      "epoch : 700.0 loss : 0.9168295447642987 Acc : 0.6346153846153846\n",
      "epoch : 800.0 loss : 0.9168295447642987 Acc : 0.6346153846153846\n",
      "class 68 model\n",
      "epoch : 100.0 loss : 0.7436324477195739 Acc : 0.8078125\n",
      "epoch : 200.0 loss : 0.7436324477195739 Acc : 0.8078125\n",
      "epoch : 300.0 loss : 0.7436324477195739 Acc : 0.8078125\n",
      "epoch : 400.0 loss : 0.7436324477195739 Acc : 0.8078125\n",
      "epoch : 500.0 loss : 0.7436324477195739 Acc : 0.8078125\n",
      "epoch : 600.0 loss : 0.7436324477195739 Acc : 0.8078125\n",
      "epoch : 700.0 loss : 0.7436324477195739 Acc : 0.8078125\n",
      "epoch : 800.0 loss : 0.7436324477195739 Acc : 0.8078125\n",
      "class 69 model\n",
      "epoch : 100.0 loss : 0.7553383874111488 Acc : 0.7961065573770492\n",
      "epoch : 200.0 loss : 0.7553383874111488 Acc : 0.7961065573770492\n",
      "epoch : 300.0 loss : 0.7553383874111488 Acc : 0.7961065573770492\n",
      "epoch : 400.0 loss : 0.7553383874111488 Acc : 0.7961065573770492\n",
      "epoch : 500.0 loss : 0.7553383874111488 Acc : 0.7961065573770492\n",
      "epoch : 600.0 loss : 0.7553383874111488 Acc : 0.7961065573770492\n",
      "epoch : 700.0 loss : 0.7553383874111488 Acc : 0.7961065573770492\n",
      "epoch : 800.0 loss : 0.7553383874111488 Acc : 0.7961065573770492\n",
      "class 70 model\n",
      "epoch : 100.0 loss : 0.8211817866877505 Acc : 0.7302631578947368\n",
      "epoch : 200.0 loss : 0.8211817866877505 Acc : 0.7302631578947368\n",
      "epoch : 300.0 loss : 0.8211817866877505 Acc : 0.7302631578947368\n",
      "epoch : 400.0 loss : 0.8211817866877505 Acc : 0.7302631578947368\n",
      "epoch : 500.0 loss : 0.8211817866877505 Acc : 0.7302631578947368\n",
      "epoch : 600.0 loss : 0.8211817866877505 Acc : 0.7302631578947368\n",
      "epoch : 700.0 loss : 0.8211817866877505 Acc : 0.7302631578947368\n",
      "epoch : 800.0 loss : 0.8211817866877505 Acc : 0.7302631578947368\n",
      "class 71 model\n",
      "epoch : 100.0 loss : 0.9537886790931225 Acc : 0.59765625\n",
      "epoch : 200.0 loss : 0.9537886790931225 Acc : 0.59765625\n",
      "epoch : 300.0 loss : 0.9537886790931225 Acc : 0.59765625\n",
      "epoch : 400.0 loss : 0.9537886790931225 Acc : 0.59765625\n",
      "epoch : 500.0 loss : 0.9537886790931225 Acc : 0.59765625\n",
      "epoch : 600.0 loss : 0.9537886790931225 Acc : 0.59765625\n",
      "epoch : 700.0 loss : 0.9537886790931225 Acc : 0.59765625\n",
      "epoch : 800.0 loss : 0.9537886790931225 Acc : 0.59765625\n",
      "class 72 model\n",
      "epoch : 100.0 loss : 0.9841372324870183 Acc : 0.5673076923076923\n",
      "epoch : 200.0 loss : 0.9841372324870183 Acc : 0.5673076923076923\n",
      "epoch : 300.0 loss : 0.9841372324870183 Acc : 0.5673076923076923\n",
      "epoch : 400.0 loss : 0.9841372324870183 Acc : 0.5673076923076923\n",
      "epoch : 500.0 loss : 0.9841372324870183 Acc : 0.5673076923076923\n",
      "epoch : 600.0 loss : 0.9841372324870183 Acc : 0.5673076923076923\n",
      "epoch : 700.0 loss : 0.9841372324870183 Acc : 0.5673076923076923\n",
      "epoch : 800.0 loss : 0.9841372324870183 Acc : 0.5673076923076923\n",
      "class 73 model\n",
      "epoch : 100.0 loss : 0.8181116143862407 Acc : 0.7333333333333333\n",
      "epoch : 200.0 loss : 0.8181116143862407 Acc : 0.7333333333333333\n",
      "epoch : 300.0 loss : 0.8181116143862407 Acc : 0.7333333333333333\n",
      "epoch : 400.0 loss : 0.8181116143862407 Acc : 0.7333333333333333\n",
      "epoch : 500.0 loss : 0.8181116143862407 Acc : 0.7333333333333333\n",
      "epoch : 600.0 loss : 0.8181116143862407 Acc : 0.7333333333333333\n",
      "epoch : 700.0 loss : 0.8181116143862407 Acc : 0.7333333333333333\n",
      "epoch : 800.0 loss : 0.8181116143862407 Acc : 0.7333333333333333\n",
      "class 74 model\n",
      "epoch : 100.0 loss : 1.0469806364604406 Acc : 0.5044642857142857\n",
      "epoch : 200.0 loss : 1.0469806364604406 Acc : 0.5044642857142857\n",
      "epoch : 300.0 loss : 1.0469806364604406 Acc : 0.5044642857142857\n",
      "epoch : 400.0 loss : 1.0469806364604406 Acc : 0.5044642857142857\n",
      "epoch : 500.0 loss : 1.0469806364604406 Acc : 0.5044642857142857\n",
      "epoch : 600.0 loss : 1.0469806364604406 Acc : 0.5044642857142857\n",
      "epoch : 700.0 loss : 1.0469806364604406 Acc : 0.5044642857142857\n",
      "epoch : 800.0 loss : 1.0469806364604406 Acc : 0.5044642857142857\n",
      "class 75 model\n",
      "epoch : 100.0 loss : 0.8769657711187998 Acc : 0.6744791666666666\n",
      "epoch : 200.0 loss : 0.8769657711187998 Acc : 0.6744791666666666\n",
      "epoch : 300.0 loss : 0.8769657711187998 Acc : 0.6744791666666666\n",
      "epoch : 400.0 loss : 0.8769657711187998 Acc : 0.6744791666666666\n",
      "epoch : 500.0 loss : 0.8769657711187998 Acc : 0.6744791666666666\n",
      "epoch : 600.0 loss : 0.8769657711187998 Acc : 0.6744791666666666\n",
      "epoch : 700.0 loss : 0.8769657711187998 Acc : 0.6744791666666666\n",
      "epoch : 800.0 loss : 0.8769657711187998 Acc : 0.6744791666666666\n",
      "class 76 model\n",
      "epoch : 100.0 loss : 0.817069947719574 Acc : 0.734375\n",
      "epoch : 200.0 loss : 0.817069947719574 Acc : 0.734375\n",
      "epoch : 300.0 loss : 0.817069947719574 Acc : 0.734375\n",
      "epoch : 400.0 loss : 0.817069947719574 Acc : 0.734375\n",
      "epoch : 500.0 loss : 0.817069947719574 Acc : 0.734375\n",
      "epoch : 600.0 loss : 0.817069947719574 Acc : 0.734375\n",
      "epoch : 700.0 loss : 0.817069947719574 Acc : 0.734375\n",
      "epoch : 800.0 loss : 0.817069947719574 Acc : 0.734375\n",
      "class 77 model\n",
      "epoch : 100.0 loss : 0.961167143450843 Acc : 0.5902777777777778\n",
      "epoch : 200.0 loss : 0.961167143450843 Acc : 0.5902777777777778\n",
      "epoch : 300.0 loss : 0.961167143450843 Acc : 0.5902777777777778\n",
      "epoch : 400.0 loss : 0.961167143450843 Acc : 0.5902777777777778\n",
      "epoch : 500.0 loss : 0.961167143450843 Acc : 0.5902777777777778\n",
      "epoch : 600.0 loss : 0.961167143450843 Acc : 0.5902777777777778\n",
      "epoch : 700.0 loss : 0.961167143450843 Acc : 0.5902777777777778\n",
      "epoch : 800.0 loss : 0.961167143450843 Acc : 0.5902777777777778\n",
      "class 78 model\n",
      "epoch : 100.0 loss : 0.9175163592611041 Acc : 0.6339285714285714\n",
      "epoch : 200.0 loss : 0.9175163592611041 Acc : 0.6339285714285714\n",
      "epoch : 300.0 loss : 0.9175163592611041 Acc : 0.6339285714285714\n",
      "epoch : 400.0 loss : 0.9175163592611041 Acc : 0.6339285714285714\n",
      "epoch : 500.0 loss : 0.9175163592611041 Acc : 0.6339285714285714\n",
      "epoch : 600.0 loss : 0.9175163592611041 Acc : 0.6339285714285714\n",
      "epoch : 700.0 loss : 0.9175163592611041 Acc : 0.6339285714285714\n",
      "epoch : 800.0 loss : 0.9175163592611041 Acc : 0.6339285714285714\n",
      "class 79 model\n",
      "epoch : 100.0 loss : 0.9160282711187998 Acc : 0.6354166666666666\n",
      "epoch : 200.0 loss : 0.9160282711187998 Acc : 0.6354166666666666\n",
      "epoch : 300.0 loss : 0.9160282711187998 Acc : 0.6354166666666666\n",
      "epoch : 400.0 loss : 0.9160282711187998 Acc : 0.6354166666666666\n",
      "epoch : 500.0 loss : 0.9160282711187998 Acc : 0.6354166666666666\n",
      "epoch : 600.0 loss : 0.9160282711187998 Acc : 0.6354166666666666\n",
      "epoch : 700.0 loss : 0.9160282711187998 Acc : 0.6354166666666666\n",
      "epoch : 800.0 loss : 0.9160282711187998 Acc : 0.6354166666666666\n",
      "class 80 model\n",
      "epoch : 100.0 loss : 0.8840342164039612 Acc : 0.6674107142857143\n",
      "epoch : 200.0 loss : 0.8840342164039612 Acc : 0.6674107142857143\n",
      "epoch : 300.0 loss : 0.8840342164039612 Acc : 0.6674107142857143\n",
      "epoch : 400.0 loss : 0.8840342164039612 Acc : 0.6674107142857143\n",
      "epoch : 500.0 loss : 0.8840342164039612 Acc : 0.6674107142857143\n",
      "epoch : 600.0 loss : 0.8840342164039612 Acc : 0.6674107142857143\n",
      "epoch : 700.0 loss : 0.8840342164039612 Acc : 0.6674107142857143\n",
      "epoch : 800.0 loss : 0.8840342164039612 Acc : 0.6674107142857143\n",
      "class 81 model\n",
      "epoch : 100.0 loss : 0.699882447719574 Acc : 0.8515625\n",
      "epoch : 200.0 loss : 0.699882447719574 Acc : 0.8515625\n",
      "epoch : 300.0 loss : 0.699882447719574 Acc : 0.8515625\n",
      "epoch : 400.0 loss : 0.699882447719574 Acc : 0.8515625\n",
      "epoch : 500.0 loss : 0.699882447719574 Acc : 0.8515625\n",
      "epoch : 600.0 loss : 0.699882447719574 Acc : 0.8515625\n",
      "epoch : 700.0 loss : 0.699882447719574 Acc : 0.8515625\n",
      "epoch : 800.0 loss : 0.699882447719574 Acc : 0.8515625\n",
      "class 82 model\n",
      "epoch : 100.0 loss : 0.8639449357986451 Acc : 0.6875\n",
      "epoch : 200.0 loss : 0.8639449357986451 Acc : 0.6875\n",
      "epoch : 300.0 loss : 0.8639449357986451 Acc : 0.6875\n",
      "epoch : 400.0 loss : 0.8639449357986451 Acc : 0.6875\n",
      "epoch : 500.0 loss : 0.8639449357986451 Acc : 0.6875\n",
      "epoch : 600.0 loss : 0.8639449357986451 Acc : 0.6875\n",
      "epoch : 700.0 loss : 0.8639449357986451 Acc : 0.6875\n",
      "epoch : 800.0 loss : 0.8639449357986451 Acc : 0.6875\n",
      "class 83 model\n",
      "epoch : 100.0 loss : 1.1972782214482625 Acc : 0.3541666666666667\n",
      "epoch : 200.0 loss : 1.1972782214482625 Acc : 0.3541666666666667\n",
      "epoch : 300.0 loss : 1.1972782214482625 Acc : 0.3541666666666667\n",
      "epoch : 400.0 loss : 1.1972782214482625 Acc : 0.3541666666666667\n",
      "epoch : 500.0 loss : 1.1972782214482625 Acc : 0.3541666666666667\n",
      "epoch : 600.0 loss : 1.1972782214482625 Acc : 0.3541666666666667\n",
      "epoch : 700.0 loss : 1.1972782214482625 Acc : 0.3541666666666667\n",
      "epoch : 800.0 loss : 1.1972782214482625 Acc : 0.3541666666666667\n",
      "class 84 model\n",
      "epoch : 100.0 loss : 1.1264449119567872 Acc : 0.425\n",
      "epoch : 200.0 loss : 1.1264449119567872 Acc : 0.425\n",
      "epoch : 300.0 loss : 1.1264449119567872 Acc : 0.425\n",
      "epoch : 400.0 loss : 1.1264449119567872 Acc : 0.425\n",
      "epoch : 500.0 loss : 1.1264449119567872 Acc : 0.425\n",
      "epoch : 600.0 loss : 1.1264449119567872 Acc : 0.425\n",
      "epoch : 700.0 loss : 1.1264449119567872 Acc : 0.425\n",
      "epoch : 800.0 loss : 1.1264449119567872 Acc : 0.425\n",
      "class 85 model\n",
      "epoch : 100.0 loss : 0.7660282810529073 Acc : 0.7854166666666667\n",
      "epoch : 200.0 loss : 0.7660282810529073 Acc : 0.7854166666666667\n",
      "epoch : 300.0 loss : 0.7660282810529073 Acc : 0.7854166666666667\n",
      "epoch : 400.0 loss : 0.7660282810529073 Acc : 0.7854166666666667\n",
      "epoch : 500.0 loss : 0.7660282810529073 Acc : 0.7854166666666667\n",
      "epoch : 600.0 loss : 0.7660282810529073 Acc : 0.7854166666666667\n",
      "epoch : 700.0 loss : 0.7660282810529073 Acc : 0.7854166666666667\n",
      "epoch : 800.0 loss : 0.7660282810529073 Acc : 0.7854166666666667\n",
      "class 86 model\n",
      "epoch : 100.0 loss : 0.7838668152689934 Acc : 0.767578125\n",
      "epoch : 200.0 loss : 0.7838668152689934 Acc : 0.767578125\n",
      "epoch : 300.0 loss : 0.7838668152689934 Acc : 0.767578125\n",
      "epoch : 400.0 loss : 0.7838668152689934 Acc : 0.767578125\n",
      "epoch : 500.0 loss : 0.7838668152689934 Acc : 0.767578125\n",
      "epoch : 600.0 loss : 0.7838668152689934 Acc : 0.767578125\n",
      "epoch : 700.0 loss : 0.7838668152689934 Acc : 0.767578125\n",
      "epoch : 800.0 loss : 0.7838668152689934 Acc : 0.767578125\n",
      "class 87 model\n",
      "epoch : 100.0 loss : 0.8056116104125977 Acc : 0.7458333333333333\n",
      "epoch : 200.0 loss : 0.8056116104125977 Acc : 0.7458333333333333\n",
      "epoch : 300.0 loss : 0.8056116104125977 Acc : 0.7458333333333333\n",
      "epoch : 400.0 loss : 0.8056116104125977 Acc : 0.7458333333333333\n",
      "epoch : 500.0 loss : 0.8056116104125977 Acc : 0.7458333333333333\n",
      "epoch : 600.0 loss : 0.8056116104125977 Acc : 0.7458333333333333\n",
      "epoch : 700.0 loss : 0.8056116104125977 Acc : 0.7458333333333333\n",
      "epoch : 800.0 loss : 0.8056116104125977 Acc : 0.7458333333333333\n",
      "class 88 model\n",
      "epoch : 100.0 loss : 0.8866722096096386 Acc : 0.6647727272727273\n",
      "epoch : 200.0 loss : 0.8866722096096386 Acc : 0.6647727272727273\n",
      "epoch : 300.0 loss : 0.8866722096096386 Acc : 0.6647727272727273\n",
      "epoch : 400.0 loss : 0.8866722096096386 Acc : 0.6647727272727273\n",
      "epoch : 500.0 loss : 0.8866722096096386 Acc : 0.6647727272727273\n",
      "epoch : 600.0 loss : 0.8866722096096386 Acc : 0.6647727272727273\n",
      "epoch : 700.0 loss : 0.8866722096096386 Acc : 0.6647727272727273\n",
      "epoch : 800.0 loss : 0.8866722096096386 Acc : 0.6647727272727273\n",
      "class 89 model\n",
      "epoch : 100.0 loss : 0.8326949385496286 Acc : 0.71875\n",
      "epoch : 200.0 loss : 0.8326949202097379 Acc : 0.71875\n",
      "epoch : 300.0 loss : 0.8302910923957825 Acc : 0.7211538461538461\n",
      "epoch : 600.0 loss : 0.8302910923957825 Acc : 0.7211538461538461\n",
      "epoch : 700.0 loss : 0.8302910923957825 Acc : 0.7211538461538461\n",
      "epoch : 800.0 loss : 0.8302910923957825 Acc : 0.7211538461538461\n",
      "class 90 model\n",
      "epoch : 100.0 loss : 1.0871591908591134 Acc : 0.4642857142857143\n",
      "epoch : 200.0 loss : 1.0871591908591134 Acc : 0.4642857142857143\n",
      "epoch : 300.0 loss : 1.0871591908591134 Acc : 0.4642857142857143\n",
      "epoch : 400.0 loss : 1.0871591908591134 Acc : 0.4642857142857143\n",
      "epoch : 500.0 loss : 1.0871591908591134 Acc : 0.4642857142857143\n",
      "epoch : 600.0 loss : 1.0871591908591134 Acc : 0.4642857142857143\n",
      "epoch : 700.0 loss : 1.0871591908591134 Acc : 0.4642857142857143\n",
      "epoch : 800.0 loss : 1.0871591908591134 Acc : 0.4642857142857143\n",
      "class 91 model\n",
      "epoch : 100.0 loss : 0.9983199238777161 Acc : 0.553125\n",
      "epoch : 200.0 loss : 0.9983199238777161 Acc : 0.553125\n",
      "epoch : 300.0 loss : 0.9983199238777161 Acc : 0.553125\n",
      "epoch : 400.0 loss : 0.9983199238777161 Acc : 0.553125\n",
      "epoch : 500.0 loss : 0.9983199238777161 Acc : 0.553125\n",
      "epoch : 600.0 loss : 0.9983199238777161 Acc : 0.553125\n",
      "epoch : 700.0 loss : 0.9983199238777161 Acc : 0.553125\n",
      "epoch : 800.0 loss : 0.9983199238777161 Acc : 0.553125\n",
      "class 92 model\n",
      "epoch : 100.0 loss : 0.8268355689942837 Acc : 0.724609375\n",
      "epoch : 200.0 loss : 0.8268355689942837 Acc : 0.724609375\n",
      "epoch : 300.0 loss : 0.8268355689942837 Acc : 0.724609375\n",
      "epoch : 400.0 loss : 0.8268355689942837 Acc : 0.724609375\n",
      "epoch : 500.0 loss : 0.8268355689942837 Acc : 0.724609375\n",
      "epoch : 600.0 loss : 0.8268355689942837 Acc : 0.724609375\n",
      "epoch : 700.0 loss : 0.8268355689942837 Acc : 0.724609375\n",
      "epoch : 800.0 loss : 0.8268355689942837 Acc : 0.724609375\n",
      "class 93 model\n",
      "epoch : 100.0 loss : 0.995194923877716 Acc : 0.55625\n",
      "epoch : 200.0 loss : 0.995194923877716 Acc : 0.55625\n",
      "epoch : 300.0 loss : 0.995194923877716 Acc : 0.55625\n",
      "epoch : 400.0 loss : 0.995194923877716 Acc : 0.55625\n",
      "epoch : 500.0 loss : 0.995194923877716 Acc : 0.55625\n",
      "epoch : 600.0 loss : 0.995194923877716 Acc : 0.55625\n",
      "epoch : 700.0 loss : 0.995194923877716 Acc : 0.55625\n",
      "epoch : 800.0 loss : 0.995194923877716 Acc : 0.55625\n",
      "class 94 model\n",
      "epoch : 100.0 loss : 0.7642425610905602 Acc : 0.7872023809523809\n",
      "epoch : 200.0 loss : 0.7642425610905602 Acc : 0.7872023809523809\n",
      "epoch : 300.0 loss : 0.7642425610905602 Acc : 0.7872023809523809\n",
      "epoch : 400.0 loss : 0.7642425610905602 Acc : 0.7872023809523809\n",
      "epoch : 500.0 loss : 0.7642425610905602 Acc : 0.7872023809523809\n",
      "epoch : 600.0 loss : 0.7642425610905602 Acc : 0.7872023809523809\n",
      "epoch : 700.0 loss : 0.7642425610905602 Acc : 0.7872023809523809\n",
      "epoch : 800.0 loss : 0.7642425610905602 Acc : 0.7872023809523809\n",
      "class 95 model\n",
      "epoch : 100.0 loss : 0.736444947719574 Acc : 0.815\n",
      "epoch : 200.0 loss : 0.736444947719574 Acc : 0.815\n",
      "epoch : 300.0 loss : 0.736444947719574 Acc : 0.815\n",
      "epoch : 400.0 loss : 0.736444947719574 Acc : 0.815\n",
      "epoch : 500.0 loss : 0.736444947719574 Acc : 0.815\n",
      "epoch : 600.0 loss : 0.736444947719574 Acc : 0.815\n",
      "epoch : 700.0 loss : 0.736444947719574 Acc : 0.815\n",
      "epoch : 800.0 loss : 0.736444947719574 Acc : 0.815\n",
      "class 96 model\n",
      "epoch : 100.0 loss : 0.9718078297953452 Acc : 0.5796370967741935\n",
      "epoch : 200.0 loss : 0.9718078297953452 Acc : 0.5796370967741935\n",
      "epoch : 300.0 loss : 0.9718078297953452 Acc : 0.5796370967741935\n",
      "epoch : 400.0 loss : 0.9718078297953452 Acc : 0.5796370967741935\n",
      "epoch : 500.0 loss : 0.9718078297953452 Acc : 0.5796370967741935\n",
      "epoch : 600.0 loss : 0.9718078297953452 Acc : 0.5796370967741935\n",
      "epoch : 700.0 loss : 0.9718078297953452 Acc : 0.5796370967741935\n",
      "epoch : 800.0 loss : 0.9718078297953452 Acc : 0.5796370967741935\n",
      "class 97 model\n",
      "epoch : 100.0 loss : 0.801444947719574 Acc : 0.75\n",
      "epoch : 200.0 loss : 0.801444947719574 Acc : 0.75\n",
      "epoch : 300.0 loss : 0.801444947719574 Acc : 0.75\n",
      "epoch : 400.0 loss : 0.801444947719574 Acc : 0.75\n",
      "epoch : 500.0 loss : 0.801444947719574 Acc : 0.75\n",
      "epoch : 600.0 loss : 0.801444947719574 Acc : 0.75\n",
      "epoch : 700.0 loss : 0.801444947719574 Acc : 0.75\n",
      "epoch : 800.0 loss : 0.801444947719574 Acc : 0.75\n",
      "class 98 model\n",
      "epoch : 100.0 loss : 1.2076948947376676 Acc : 0.34375\n",
      "epoch : 200.0 loss : 1.2076948947376676 Acc : 0.34375\n",
      "epoch : 300.0 loss : 1.2076948947376676 Acc : 0.34375\n",
      "epoch : 400.0 loss : 1.2076948947376676 Acc : 0.34375\n",
      "epoch : 500.0 loss : 1.2076948947376676 Acc : 0.34375\n",
      "epoch : 600.0 loss : 1.2076948947376676 Acc : 0.34375\n",
      "epoch : 700.0 loss : 1.2076948947376676 Acc : 0.34375\n",
      "epoch : 800.0 loss : 1.2076948947376676 Acc : 0.34375\n",
      "class 99 model\n",
      "epoch : 100.0 loss : 0.7499743594842798 Acc : 0.8014705882352942\n",
      "epoch : 200.0 loss : 0.7499743594842798 Acc : 0.8014705882352942\n",
      "epoch : 300.0 loss : 0.7499743594842798 Acc : 0.8014705882352942\n",
      "epoch : 400.0 loss : 0.7499743594842798 Acc : 0.8014705882352942\n",
      "epoch : 500.0 loss : 0.7499743594842798 Acc : 0.8014705882352942\n",
      "epoch : 600.0 loss : 0.7499743594842798 Acc : 0.8014705882352942\n",
      "epoch : 700.0 loss : 0.7499743594842798 Acc : 0.8014705882352942\n",
      "epoch : 800.0 loss : 0.7499743594842798 Acc : 0.8014705882352942\n"
     ]
    }
   ],
   "source": [
    "#train分類模型\n",
    "\n",
    "Epochs=800\n",
    "max_test_acc=0.0\n",
    "class_number = 100\n",
    "train_loss_list=[]\n",
    "train_acc_list=[]\n",
    "test_loss_list=[]\n",
    "test_acc_list=[]\n",
    "batch_size = 32\n",
    "device = 'cuda'\n",
    "model_path = 'linear_weight/cifar100_ece'\n",
    "test = []\n",
    "\n",
    "'''匯入所有label'''\n",
    "train_label_ = []\n",
    "for t in range(class_number):\n",
    "    with open('pickle/cifar100_test/class'+str(t)+'/cifar100_class'+str(t)+'_label.pickle', 'rb') as f:\n",
    "        train_label_.append(pickle.load(f))\n",
    "\n",
    "\n",
    "val_label_ = []\n",
    "for t in range(class_number):\n",
    "    with open('pickle/cifar100_test/class'+str(t)+'/cifar100_val_class'+str(t)+'_label.pickle', 'rb') as f:\n",
    "        val_label_.append(pickle.load(f))\n",
    "\n",
    "\n",
    "'''匯入所有confidence'''\n",
    "train_tensor_ = []\n",
    "for t in range(class_number):\n",
    "    with open('pickle/cifar100_test/class'+str(t)+'/cifar100_class'+str(t)+'_tensor.pickle', 'rb') as f:\n",
    "        train_tensor_.append(pickle.load(f))\n",
    "\n",
    "\n",
    "val_tensor_ = []\n",
    "for t in range(class_number):\n",
    "    with open('pickle/cifar100_test/class'+str(t)+'/cifar100_val_class'+str(t)+'_tensor.pickle', 'rb') as f:\n",
    "        val_tensor_.append(pickle.load(f))\n",
    "\n",
    "\n",
    "#訓練各類模型\n",
    "for class_n in range(class_number):\n",
    "    print('class '+str(class_n)+' model')\n",
    "\n",
    "    # 按batch size包裝training set資料\n",
    "    register_1 = []\n",
    "    register_2 = []\n",
    "    train_tensor_list = []\n",
    "    train_label_list = []\n",
    "    count = 0\n",
    "    best_acc = 0\n",
    "    for t in range(len(train_tensor_[class_n])):\n",
    "        count+=1\n",
    "\n",
    "        #不做confidence calibration\n",
    "        # numpy = FUN.softmax(Variable(train_tensor_[class_n][t])).data.cpu().numpy()#把input從confidence轉為機率\n",
    "\n",
    "        #做confidence calibration\n",
    "        caliration = train_tensor_[class_n][t]/0.5\n",
    "        soft = FUN.softmax(Variable(caliration)).data.cpu()#把input從confidence轉為機率\n",
    "        numpy = soft.numpy()\n",
    "\n",
    "        # 對input做confidence calibration( 只取confidence高的 )\n",
    "        value , index = torch.sort(train_tensor_[class_n][t].squeeze(),descending = True)\n",
    "        for t2 in range(len(index)):\n",
    "            if t2>20:\n",
    "                pass\n",
    "            else:\n",
    "                numpy[0][index[t2]] = numpy[0][index[t2]]\n",
    "\n",
    "\n",
    "        tensor = torch.tensor(numpy)\n",
    "        # tensor = train_tensor_[class_n][t]\n",
    "        register_1.append(tensor)\n",
    "        register_2.append(train_label_[class_n][t])\n",
    "        if count % batch_size ==0:\n",
    "            a = torch.stack(register_1)\n",
    "            b = torch.stack(register_2)\n",
    "            train_tensor_list.append(a)\n",
    "            train_label_list.append(b)\n",
    "            register_1 = []\n",
    "            register_2 = []\n",
    "\n",
    "    #依bach size打包validation set\n",
    "    register_1 = []\n",
    "    register_2 = []\n",
    "    val_tensor_list = []\n",
    "    val_label_list = []\n",
    "    count = 0\n",
    "    for t in range(len(val_tensor_[class_n])):\n",
    "        count+=1\n",
    "\n",
    "        #不做confidence calibration\n",
    "        #numpy = FUN.softmax(Variable(val_tensor_[class_n][t])).data.cpu().numpy()#把input從confidence轉為機率\n",
    "\n",
    "        #做confidence calibration\n",
    "        caliration = val_tensor_[class_n][t]/0.5\n",
    "        soft = FUN.softmax(Variable(caliration)).data.cpu()#把input從confidence轉為機率\n",
    "        numpy = soft.numpy()\n",
    "\n",
    "\n",
    "        # 對input做confidence calibration( 只取confidence高的 )\n",
    "        value , index = torch.sort(val_tensor_[class_n][t].squeeze(),descending = True)\n",
    "        for t2 in range(len(index)):\n",
    "            if t2>20:\n",
    "                pass\n",
    "            else:\n",
    "                numpy[0][index[t2]] = numpy[0][index[t2]]\n",
    "\n",
    "\n",
    "\n",
    "        tensor = torch.tensor(numpy)\n",
    "        # tensor = val_tensor_[class_n][t]\n",
    "        register_1.append(tensor)\n",
    "        register_2.append(val_label_[class_n][t])\n",
    "        if count % batch_size ==0:\n",
    "            a = torch.stack(register_1)\n",
    "            b = torch.stack(register_2)\n",
    "            val_tensor_list.append(a)\n",
    "            val_label_list.append(b)\n",
    "            register_1 = []\n",
    "            register_2 = []\n",
    "\n",
    "\n",
    "    register = 0\n",
    "    #開始訓練模型\n",
    "    for epoch in range(Epochs):\n",
    "        optimizer1 = lrfn(epoch,optimizer)\n",
    "        train_loss=0.0\n",
    "        train_acc=0.0\n",
    "        test_loss=0.0\n",
    "        test_acc=0.0\n",
    "        MyResModel.train()\n",
    "        count = 0\n",
    "        train_loss_count = 0\n",
    "        train_acc_count = 0\n",
    "        for data_ in train_tensor_list:\n",
    "            optimizer1.zero_grad()\n",
    "            pred = MyResModel(data_.to(device))\n",
    "\n",
    "            max_,class_ = torch.max(pred.data,1)\n",
    "            train_correct = (class_==train_label_list[count].to(device)).sum()\n",
    "            train_acc = train_correct / batch_size\n",
    "            train_acc_count = train_acc_count + train_acc.item()\n",
    "\n",
    "            loss = criterion(pred.to(device),train_label_list[count].to(device))\n",
    "            train_loss_count = train_loss_count+loss.item()\n",
    "\n",
    "            count+=1\n",
    "            loss.backward()\n",
    "            optimizer1.step()\n",
    "        MyResModel.eval()\n",
    "        a = (epoch+1) / 100\n",
    "\n",
    "        if count ==0 :\n",
    "            count = 1\n",
    "\n",
    "        if (epoch+1) % 10 ==0:\n",
    "            pass\n",
    "            # print('epoch : '+ str(int(a*100)) +' train_loss : '+str(train_loss_count/count)+' train_Acc : '+str(train_acc_count/count))\n",
    "\n",
    "        #算驗證集loss和acc\n",
    "        if (epoch+1) % 100 ==0:\n",
    "            count = 0\n",
    "            loss_count = 0\n",
    "            acc_count = 0\n",
    "            for data_ in val_tensor_list:\n",
    "                pred = MyResModel(data_.to(device))\n",
    "                max_,class_ = torch.max(pred.data,1)\n",
    "                correct = (class_==val_label_list[count].to(device)).sum()\n",
    "                acc = correct / batch_size\n",
    "                acc_count = acc_count + acc.item()\n",
    "                loss = criterion(pred.to(device),val_label_list[count].to(device))\n",
    "                loss_count = loss_count+loss.item()\n",
    "                count+=1\n",
    "\n",
    "            if count ==0 :\n",
    "                count = 1\n",
    "\n",
    "            if acc_count/count >= best_acc:\n",
    "                best_acc = acc_count/count\n",
    "                torch.save(MyResModel.state_dict(), model_path+'/'+'model'+str(class_n)+'.pth')\n",
    "                a = (epoch+1) / 100\n",
    "                print('epoch : '+ str(a*100) +' loss : '+str(loss_count/count)+' Acc : '+str(acc_count/count))\n",
    "                register = acc_count/count\n",
    "\n",
    "                \n",
    "    if register >=0.7:\n",
    "        test.append(str(class_n)) #test是紀錄線性模型中準確率好的class\n",
    "with open('pickle/good_model/good_model_list_ece.pickle', 'wb') as f:\n",
    "    pickle.dump(test, f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": [
    "#生成一個效能好的model的list\n",
    "with open('pickle/good_model/good_model_list_ece.pickle', 'rb') as f:  \n",
    "    good_model = pickle.load(f)\n",
    "\n",
    "print(len(good_model))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50000 [00:00<?, ?it/s]c:\\Users\\Taka\\anaconda3\\envs\\taka1\\lib\\site-packages\\ipykernel_launcher.py:33: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "100%|██████████| 50000/50000 [1:46:34<00:00,  7.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31052\n",
      "acc : 0.62104\n"
     ]
    }
   ],
   "source": [
    "#用train出的模型修改本來的confidence( 修改前5大的 )\n",
    "\n",
    "with open('pickle/cifar100_all/cifar100_all_tensor.pickle', 'rb') as f:  \n",
    "    result = pickle.load(f)\n",
    "\n",
    "with open('pickle\\cifar100_all/cifar100_all_class_label.pickle', 'rb') as f:\n",
    "    label = pickle.load(f)\n",
    "\n",
    "with open('pickle\\cifar100_all/cifar100_all_path.pickle', 'rb') as f:\n",
    "    path = pickle.load(f)\n",
    "\n",
    "\n",
    "weight_dir = 'linear_weight/cifar100_test'\n",
    "weight_path = os.listdir(weight_dir)\n",
    "model_file = []\n",
    "count0 = 0\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "count3 = 0\n",
    "count4 = 0\n",
    "\n",
    "for t in range(len(weight_path)):\n",
    "    path = weight_dir + '/' + weight_path[t]\n",
    "    model_file.append(path)\n",
    "\n",
    "for t in tqdm(range(len(result))):     \n",
    "    value , index = torch.sort(result[t].squeeze(),descending = True)\n",
    "    for t2 in range(int(len(index)/20)):\n",
    "        \n",
    "        MyResModel.load_state_dict(torch.load(model_file[int(index[t2])]))\n",
    "\n",
    "        MyResModel = MyResModel.to(device)\n",
    "        numpy = FUN.softmax(Variable(result[t])).data.cpu().numpy()\n",
    "        tensor = torch.tensor(numpy)\n",
    "        tensor = tensor.unsqueeze(0)\n",
    "        tensor = tensor.to(device)\n",
    "        output = MyResModel(tensor)\n",
    "        pre_class = torch.argmax(output)\n",
    "\n",
    "\n",
    "        #只修改模型效果好的\n",
    "\n",
    "        if index[t2] in good_model:\n",
    "            if int(pre_class)==0:\n",
    "                result[t][0][int(index[t2])] = result[t][0][int(index[t2])] + result[t][0][int(index[t2])]*0.5\n",
    "                count0+=1\n",
    "            if int(pre_class)==1:\n",
    "                result[t][0][int(index[t2])] = result[t][0][int(index[t2])]\n",
    "                count1+=1\n",
    "            if int(pre_class)==2:\n",
    "                result[t][0][int(index[t2])] = result[t][0][int(index[t2])]- result[t][0][int(index[t2])]*0.2\n",
    "                count2+=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "acc_count = 0\n",
    "for t in range(len(result)):        \n",
    "        r = torch.argmax(result[t])\n",
    "        if int(r) == label[t]:\n",
    "            acc_count+=1\n",
    "print(acc_count)\n",
    "print('acc : '+str(acc_count/len(result)))\n",
    "\n",
    "with open('pickle/cifar100_all/alldata_revise_max5_good_model_warmup.pickle', 'wb') as f:\n",
    "    pickle.dump(result, f)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Taka\\anaconda3\\envs\\taka1\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "#用改完的confidence算enstropy挑 x% data(各類數量平均)\n",
    "\n",
    "with open('pickle\\cifar100_all/cifar100_all_class_label.pickle', 'rb') as f:\n",
    "    label = pickle.load(f)\n",
    "\n",
    "with open('pickle\\cifar100_all/cifar100_all_path.pickle', 'rb') as f:\n",
    "    path = pickle.load(f)\n",
    "\n",
    "with open('pickle\\cifar100_all/alldata_revise_max5_just_good_model.pickle', 'rb') as f:\n",
    "    result = pickle.load(f)\n",
    "\n",
    "class_num = 100\n",
    "\n",
    "\n",
    "\n",
    "img_save_dir = 'cifar_100/cifar100_50percent_just_good_model/train' \n",
    "img_dir = 'cifar_100/train_class/train'\n",
    "all_en = []\n",
    "for t in range(len(result)):\n",
    "    odds = FUN.softmax(Variable(result[t]).cpu()).data.numpy()\n",
    "    odds = odds.reshape([class_num])\n",
    "    data_entropy = entropy(odds)\n",
    "    all_en.append(data_entropy)\n",
    "sort = sorted(range(len(all_en)) , reverse = True,key = lambda k : all_en[k])\n",
    "\n",
    "img_dir_list=glob.glob(img_dir+os.sep+\"*\")#獲取每個類别所在的路徑（一個類别對應一個文件夾）\n",
    "for class_dir in img_dir_list:\n",
    "    class_name=class_dir.split(os.sep)[-1] #獲取當前類别\n",
    "    save_train=img_save_dir+os.sep+os.sep+class_name\n",
    "    os.makedirs(save_train,exist_ok=True)#建立對應的文件夾\n",
    "\n",
    "con = [0 for t in range(class_num)]\n",
    "for t in range(int(len(sort))):\n",
    "    p = re.sub(\"\\,\",\"\",str(path [sort[t]]))\n",
    "    p = re.sub(\"\\(\",\"\",p)\n",
    "    p = re.sub(\"\\)\",\"\",p)\n",
    "    p = re.sub(\"\\'\",\"\",p)\n",
    "    split = p.split('\\\\')\n",
    "\n",
    "    if con[int(split[4])] <= (int(len(sort))/class_num) *0.5:\n",
    "\n",
    "        con[int(split[4])] = con[int(split[4])]+1\n",
    "        img = cv2.imread(p)\n",
    "        cv2.imwrite(img_save_dir+'/'+ split[4]+'/'+split[6], img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssss\n"
     ]
    }
   ],
   "source": [
    "s = 'ssss'\n",
    "a = s\n",
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('taka1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2932b575bb3a877f7f2eb58752af01fc0ca4cbf58bab91fbf4e91b10a7e35e59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
