{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用到的套件\n",
    "\n",
    "from __future__ import print_function, division\n",
    "import os  \n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "import torchvision\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "from pathlib import Path\n",
    "from torchvision import datasets,transforms\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import time\n",
    "import argparse\n",
    "from time import sleep\n",
    "from tqdm import tqdm, trange\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as FUN\n",
    "from scipy import io\n",
    "import efficientnet_pytorch\n",
    "import torchvision.transforms as T\n",
    "import PIL\n",
    "import pickle\n",
    "import torchvision.datasets as dsets\n",
    "from scipy.misc import imsave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定義function\n",
    "\n",
    "def load_file(filename):\n",
    "    with open(filename, 'rb') as fo:\n",
    "        data = pickle.load(fo, encoding='latin1')\n",
    "    return data\n",
    "\n",
    "# 解壓縮，返回解壓後的字典\n",
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "#補邊,填充成正方形，防止resize變形\n",
    "def expend_img(img):\n",
    "    '''\n",
    "    :param img: 图片数据\n",
    "    :return:\n",
    "    '''\n",
    "    fill_pix=[0,0,0] #填充色素，可自己設定\n",
    "    h,w=img.shape[:2]\n",
    "    if h>=w: #左右填充\n",
    "        padd_width=int(h-w)//2\n",
    "        padd_top,padd_bottom,padd_left,padd_right=0,0,padd_width,padd_width #各個方向的填充像素\n",
    "    elif h<w: #上下填充\n",
    "        padd_high=int(w-h)//2\n",
    "        padd_top,padd_bottom,padd_left,padd_right=padd_high,padd_high,0,0 #各個方向的填充像素\n",
    "    new_img = cv2.copyMakeBorder(img,padd_top,padd_bottom,padd_left,padd_right,cv2.BORDER_CONSTANT, value=fill_pix)\n",
    "    return new_img\n",
    "\n",
    "#對影像做基本的旋轉 和亮度 對比度 飽和度的調整\n",
    "def expend1_img(img):\n",
    "    '''\n",
    "    :param img: 圖片數據\n",
    "    :return:\n",
    "    '''\n",
    "    a = random.random()\n",
    "    \n",
    "    t2 = transforms.RandomHorizontalFlip(p=0.5)  # 水平镜像，p是機率\n",
    "    t3 = transforms.RandomVerticalFlip(p=0.2) #垂直鏡像\n",
    "    # print(type(img))\n",
    "    img = t2(img)\n",
    "    img = t3(img)\n",
    "    if a<0.4:\n",
    "        t1 = transforms.RandomRotation(45)  # 随機旋轉，旋轉範圍為【-45,45】\n",
    "        img = t1(img)\n",
    "\n",
    "    t4 = transforms.ColorJitter(brightness=(0.8,1.5), contrast=(0.8,1.5), saturation=(0.8,1.5))#調整亮度  對比度  飽和度\n",
    "    img = t4(img)\n",
    "    return img\n",
    "\n",
    "#對圖片做透視轉換\n",
    "def expend2_img(img):\n",
    "    t = transforms.RandomPerspective(distortion_scale=0.6,p=1,interpolation = 2,fill=0) #圖片透視化\n",
    "    img2 = t(img)\n",
    "    return img2\n",
    "\n",
    "#切分訓練集和測試集，並進行補邊處理\n",
    "def split_train_test(img_dir,save_dir,train_val_num):\n",
    "    '''\n",
    "    :param img_dir: 原始图片路径，注意是所有类别所在文件夹的上一级目录\n",
    "    :param save_dir: 保存图片路径\n",
    "    :param train_val_num: 切分比例\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    img_dir_list=glob.glob(img_dir+os.sep+\"*\")#獲取每個類别所在的路徑（一個類别對應一個文件夾）\n",
    "    for class_dir in img_dir_list:\n",
    "        class_name=class_dir.split(os.sep)[-1] #獲取當前類别\n",
    "        img_list=glob.glob(class_dir+os.sep+\"*\") #獲取每個類别文件夾下的所有圖片\n",
    "        all_num=len(img_list) #獲取總個數\n",
    "        train_list=random.sample(img_list,int(all_num*train_val_num)) #訓練集圖片所在路徑\n",
    "        save_train=save_dir+os.sep+'train'+os.sep+class_name\n",
    "        save_val=save_dir+os.sep+\"val\"+os.sep+class_name\n",
    "        os.makedirs(save_train,exist_ok=True)\n",
    "        os.makedirs(save_val,exist_ok=True) #建立對應的文件夾\n",
    "        #保存切分好的數據集\n",
    "        for imgpath in img_list:\n",
    "            imgname=Path(imgpath).name #獲取文件名\n",
    "            if imgpath in train_list:\n",
    "                img=cv2.imread(imgpath)\n",
    "                new_img=expend_img(img)\n",
    "                cv2.imwrite(save_train+os.sep+imgname,new_img)\n",
    "            else: #將除了訓練集意外的數據均視為驗證集\n",
    "                img = cv2.imread(imgpath)\n",
    "                new_img = expend_img(img)\n",
    "                cv2.imwrite(save_val + os.sep + imgname, new_img)\n",
    "                \n",
    "    print(\"split train and val finished !\")\n",
    "\n",
    "#資料增強\n",
    "def data_enhancement(img_dir,save_dir,train_val_num):\n",
    "\n",
    "    img_dir_list=glob.glob(img_dir+os.sep+\"*\")#獲取每个類别所在的路徑（一個類别對應一個文件夾）\n",
    "    for class_dir in img_dir_list:\n",
    "        class_name=class_dir.split(os.sep)[-1] #獲取當前類别\n",
    "        img_list=glob.glob(class_dir+os.sep+\"*\") #獲取每個類别文件夾下的所有圖片\n",
    "        all_num=len(img_list) #獲取總個數\n",
    "        train_list=random.sample(img_list,int(all_num*train_val_num)) #訓練集圖片所在路徑\n",
    "        save_train=save_dir+os.sep+\"train\"+os.sep+class_name\n",
    "        save_val=save_dir+os.sep+\"val\"+os.sep+class_name\n",
    "        os.makedirs(save_train,exist_ok=True)\n",
    "        os.makedirs(save_val,exist_ok=True) #建立對應的文件夾\n",
    "        # print(class_name+\" trian num\",len(train_list))\n",
    "        # print(class_name+\" val num\",all_num-len(train_list))\n",
    "        #保存切分好的數據集\n",
    "        for imgpath in img_list:\n",
    "            imgname=Path(imgpath).name #獲取文件名\n",
    "            if imgpath in train_list:\n",
    "                img= Image.open(imgpath)\n",
    "                for time in range(3):\n",
    "                    new_img=expend1_img(img)\n",
    "                    Image.Image.save(new_img,save_train+os.sep+str(time)+imgname)\n",
    "\n",
    "#資料增強( 透視轉換 )\n",
    "def perspective_transform(img_dir,save_dir,train_val_num):\n",
    "    \n",
    "    img_dir_list=glob.glob(img_dir+os.sep+\"*\")#獲取每个類别所在的路徑（一個類别對應一個文件夾）\n",
    "    for class_dir in img_dir_list:\n",
    "        class_name=class_dir.split(os.sep)[-1] #獲取當前類别\n",
    "        img_list=glob.glob(class_dir+os.sep+\"*\") #獲取每個類别文件夾下的所有圖片\n",
    "        all_num=len(img_list) #獲取總個數\n",
    "        train_list=random.sample(img_list,int(all_num*train_val_num)) #訓練集圖片所在路徑\n",
    "        save_train=save_dir+os.sep+\"train\"+os.sep+class_name\n",
    "        save_val=save_dir+os.sep+\"val\"+os.sep+class_name\n",
    "        os.makedirs(save_train,exist_ok=True)\n",
    "        os.makedirs(save_val,exist_ok=True) #建立對應的文件夾\n",
    "        # print(class_name+\" trian num\",len(train_list))\n",
    "        # print(class_name+\" val num\",all_num-len(train_list))\n",
    "        #保存切分好的數據集\n",
    "        for imgpath in img_list:\n",
    "            imgname=Path(imgpath).name #獲取文件名\n",
    "            if imgpath in train_list:\n",
    "                img= Image.open(imgpath)\n",
    "                for time in range(1):\n",
    "                    img2 = expend2_img(img)\n",
    "                    Image.Image.save(img2,save_train+os.sep+str(time)+'_per_'+imgname)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將data分到對應的類別的資料夾\n",
    "\n",
    "img_dir = 'cifar_10/test'\n",
    "img_path_list = glob.glob(img_dir+os.sep+\"*\")\n",
    "img_list= os.listdir(img_dir)\n",
    "save_dir = 'cifar_10/test_class'\n",
    "\n",
    "for t in range(10):\n",
    "    os.makedirs(save_dir+'/'+str(t),exist_ok=True)\n",
    "\n",
    "count = 0\n",
    "for path in img_path_list:\n",
    "    img=cv2.imread(path)\n",
    "    new_img=expend_img(img)\n",
    "    cv2.imwrite(save_dir+'/'+str(img_list[count][0])+'/'+img_list[count],new_img)\n",
    "    count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將資料集全部資料合併成一份\n",
    "\n",
    "# img_dir = 'imagenette2-320/train'\n",
    "img_dir = 'imagenette2-320/val'\n",
    "save_dir = 'imagenette_all'\n",
    "img_dir_list=glob.glob(img_dir+os.sep+\"*\")#獲取每個類别所在的路徑（一個類别對應一個文件夾）\n",
    "for class_dir in img_dir_list:\n",
    "    class_name=class_dir.split(os.sep)[-1] #獲取當前類别\n",
    "    img_list=glob.glob(class_dir+os.sep+\"*\") #獲取每個類别文件夾下的所有圖片\n",
    "    all_num=len(img_list) #獲取總個數\n",
    "    save_train=save_dir+os.sep+os.sep+class_name\n",
    "    save_val=save_dir+os.sep+os.sep+class_name\n",
    "    os.makedirs(save_train,exist_ok=True)\n",
    "    os.makedirs(save_val,exist_ok=True) #建立對應的文件夾\n",
    "    #保存切分好的數據集\n",
    "    for imgpath in img_list:\n",
    "        imgname=Path(imgpath).name #獲取文件名\n",
    "        img=cv2.imread(imgpath)\n",
    "        new_img=expend_img(img)\n",
    "        cv2.imwrite(save_train+os.sep+imgname,new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將train資料集取出10%，和5% 5%分開(各類平均)\n",
    "\n",
    "img_dir = 'cifar_10\\cifar10'\n",
    "save_dir = 'cifar_10\\cifar10_random_50percent' \n",
    "save_dir2 = 'cifar_10\\cifar10_second_5percent' \n",
    "# save_dir = 'imagenette_10percent/second_5percent' \n",
    "train_val_num = 0.5\n",
    "\n",
    "img_dir_list=glob.glob(img_dir+os.sep+\"*\")#獲取每個類别所在的路徑（一個類别對應一個文件夾）\n",
    "for class_dir in img_dir_list:\n",
    "    class_name=class_dir.split(os.sep)[-1] #獲取當前類别\n",
    "    img_list=glob.glob(class_dir+os.sep+\"*\") #獲取每個類别文件夾下的所有圖片\n",
    "    all_num=len(img_list) #獲取總個數\n",
    "    train_list=random.sample(img_list,int(all_num*train_val_num)) #訓練集圖片所在路徑\n",
    "    save_one=save_dir+os.sep+os.sep+class_name\n",
    "    save_two=save_dir2+os.sep+os.sep+class_name\n",
    "    os.makedirs(save_one,exist_ok=True)\n",
    "    # os.makedirs(save_two,exist_ok=True) #建立對應的文件夾\n",
    "\n",
    "    # print(class_name+\" trian num\",len(train_list))\n",
    "    # print(class_name+\" val num\",all_num-len(train_list))\n",
    "    \n",
    "    #保存切分好的數據集\n",
    "    for imgpath in img_list:\n",
    "        imgname=Path(imgpath).name #獲取文件名\n",
    "        if imgpath in train_list:\n",
    "            img=cv2.imread(imgpath)\n",
    "            new_img=expend_img(img)\n",
    "            cv2.imwrite(save_one+os.sep+imgname,new_img)\n",
    "        # else:\n",
    "        #     img=cv2.imread(imgpath)\n",
    "        #     new_img=expend_img(img)\n",
    "        #     cv2.imwrite(save_two+os.sep+imgname,new_img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split train and val finished !\n"
     ]
    }
   ],
   "source": [
    "#將資料集切成train和val\n",
    "\n",
    "img_dir = r'C:/Users/Taka/Desktop/efficientnet/ntust/data/og_data'\n",
    "save_dir = r'C:/Users/Taka/Desktop/efficientnet/ntust/data/split_data' \n",
    "# img_dir = 'imagenette_10percent/second_5percent'\n",
    "# save_dir = 'imagenette_10percent/second_5percent_split' \n",
    "train_val_num = 0.8\n",
    "split_train_test(img_dir,save_dir,train_val_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Taka\\anaconda3\\envs\\taka1\\lib\\site-packages\\torchvision\\transforms\\transforms.py:734: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
     ]
    }
   ],
   "source": [
    "#圖片資料增強\n",
    "\n",
    "img_dir = 'cifar_10\\cifar10_50percent_split/train'\n",
    "save_dir = 'cifar_10\\cifar10_50percent_split' \n",
    "train_val_num = 1.0\n",
    "data_enhancement(img_dir,save_dir,train_val_num)\n",
    "perspective_transform(img_dir,save_dir,train_val_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#efficientionnet訓練模型\n",
    "\n",
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = 'cpu'\n",
    "\n",
    "class Efficientnet_train():\n",
    "    def __init__(self,opt):\n",
    "        self.epochs=opt.epochs #訓練週期\n",
    "        self.batch_size=opt.batch_size #batch_size\n",
    "        self.class_num=opt.class_num #類别數\n",
    "        self.imgsz=opt.imgsz #圖片尺寸\n",
    "        self.img_dir=opt.img_dir #圖片路徑\n",
    "        self.weights=opt.weights #模型路徑\n",
    "        self.save_dir=opt.save_dir #保存模型路徑\n",
    "        self.lr=opt.lr #初始化學習率\n",
    "        self.moment=opt.m #動量\n",
    "        base_model = EfficientNet.from_name('efficientnet-b5') #加載模型，使用b幾的就改為b幾\n",
    "        state_dict = torch.load(self.weights)\n",
    "        base_model.load_state_dict(state_dict)\n",
    "        # 修改全連接層\n",
    "        num_ftrs = base_model._fc.in_features\n",
    "        base_model._fc = nn.Linear(num_ftrs, self.class_num)\n",
    "        print(device)\n",
    "        self.model = base_model.to(device)\n",
    "        # 交叉熵損失函數\n",
    "        self.cross = nn.CrossEntropyLoss()\n",
    "        # 優化器\n",
    "        self.optimzer = optim.SGD((self.model.parameters()), lr=self.lr, momentum=self.moment, weight_decay=0.0004)\n",
    "\n",
    "        #獲取處理後的數據集和類别映射表\n",
    "        self.trainx,self.valx,self.b=self.process()\n",
    "        print(self.b)\n",
    "    def __call__(self):\n",
    "        best_acc = 0\n",
    "        self.model.train(True)\n",
    "        for ech in tqdm(range(self.epochs)):\n",
    "            optimzer1 = self.lrfn(ech, self.optimzer)\n",
    "\n",
    "            print(\"----------Start Train Epoch %d----------\" % (ech + 1))\n",
    "            # 開始訓練\n",
    "            run_loss = 0.0  # 損失\n",
    "            run_correct = 0.0  # 準確率\n",
    "            count = 0.0  # 分類正確的個數\n",
    "\n",
    "            for i, data in enumerate(self.trainx):\n",
    "                # print('train')\n",
    "                inputs, label = data\n",
    "                inputs, label = inputs.to(device), label.to(device)\n",
    "\n",
    "                # 訓練\n",
    "                optimzer1.zero_grad()\n",
    "                output = self.model(inputs)\n",
    "\n",
    "                loss = self.cross(output, label)\n",
    "                loss.backward()\n",
    "                optimzer1.step()\n",
    "\n",
    "                run_loss += loss.item()  # 損失累加\n",
    "                _, pred = torch.max(output.data, 1)\n",
    "                count += label.size(0)  # 求總共的訓練個數\n",
    "                run_correct += pred.eq(label.data).cpu().sum()  # 截止當前預測正確的個數\n",
    "                #每隔100個batch顯示一次信息，這裡顯示的ACC是當前預測正確的個數/當前訓練過的個數\n",
    "                if (i+1)%100==0:\n",
    "                    print('[Epoch:{}__iter:{}/{}] | Acc:{}'.format(ech + 1,i+1,len(self.trainx), run_correct/count))\n",
    "            # print(run_correct,'------------',count)\n",
    "            train_acc = run_correct / count\n",
    "            # 每次訓完一批顯示一次信息\n",
    "            print('Epoch:{} | Loss:{} | Acc:{}'.format(ech + 1, run_loss / len(self.trainx), train_acc))\n",
    "\n",
    "            # 訓完一批次後進行驗證\n",
    "            print(\"----------Waiting Test Epoch {}----------\".format(ech + 1))\n",
    "            with torch.no_grad():\n",
    "                correct = 0.  # 預測正確的個數\n",
    "                total = 0.  # 總個數\n",
    "                for inputs, labels in self.valx:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    outputs = self.model(inputs)\n",
    "\n",
    "                    # 穫取最高分的那個類的索引\n",
    "                    _, pred = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += pred.eq(labels).cpu().sum()\n",
    "                test_acc = correct / total\n",
    "                print(\"批次%d的验证集准确率\" % (ech + 1), correct / total)\n",
    "            if best_acc < test_acc:\n",
    "                best_acc = test_acc\n",
    "                start_time=(time.strftime(\"%m%d\",time.localtime()))\n",
    "                save_weight=self.save_dir+os.sep+start_time #保存路徑\n",
    "                os.makedirs(save_weight,exist_ok=True)\n",
    "                torch.save(self.model.state_dict(), save_weight + os.sep + \"efficientb5_cifar100_10percent.pth\")#不加state_dict()存法會直接把模型架構和權重一起存入weight檔中\n",
    "                                                                                                       #加state_dict()則只單純存權重(不易報錯)\n",
    "    #數據處理\n",
    "    def process(self):\n",
    "        # 數據增强\n",
    "        data_transforms = {\n",
    "            'train': transforms.Compose([\n",
    "                transforms.Resize((self.imgsz, self.imgsz)),  # resize\n",
    "                transforms.CenterCrop((self.imgsz, self.imgsz)),  # 中心裁剪\n",
    "                transforms.RandomRotation(45),  # 随機旋轉，旋轉範圍為【-45,45】\n",
    "                transforms.ToTensor(),  # 轉換為張量\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 標準化\n",
    "            ]),\n",
    "            \"val\": transforms.Compose([\n",
    "                transforms.Resize((self.imgsz, self.imgsz)),  # resize\n",
    "                transforms.CenterCrop((self.imgsz, self.imgsz)),  # 中心裁剪\n",
    "                transforms.ToTensor(),  # 張量轉換\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        }\n",
    "        # print('123',os.listdir(os.path.join(self.img_dir, 'train')))\n",
    "        # 定義圖像生成器\n",
    "        image_datasets = {x: datasets.ImageFolder(root=os.path.join('cifar_100\\cifar100_10percent',x), transform=data_transforms[x]) for x in ['train', 'val']}\n",
    "        # print(type(image_datasets))\n",
    "        # 得到訓練集和驗證集\n",
    "        trainx = DataLoader(image_datasets[\"train\"], batch_size=self.batch_size, shuffle=True, drop_last=True)\n",
    "        valx = DataLoader(image_datasets[\"val\"], batch_size=self.batch_size, shuffle=True, drop_last=False)\n",
    "        # print(image_datasets[\"train\"])\n",
    "        # print('trainx',len(trainx))\n",
    "        # print('valx',len(valx))\n",
    "        # print(self.batch_size)\n",
    "        b = image_datasets[\"train\"].class_to_idx  # id和類别對\n",
    "        return trainx,valx,b\n",
    "\n",
    "\n",
    "    # 學習率慢热加下降\n",
    "    def lrfn(self,num_epoch, optimzer):\n",
    "        lr_start = 0.00001  # 初始值\n",
    "        max_lr = 0.0004  # 最大值\n",
    "        lr_up_epoch = 10  # 學習率上升10个epoch\n",
    "        lr_sustain_epoch = 5  # 學習率保持不變\n",
    "        lr_exp = .8  # 衰减因子\n",
    "        if num_epoch < lr_up_epoch:  # 0-10个epoch學習率線性增加\n",
    "            lr = (max_lr - lr_start) / lr_up_epoch * num_epoch + lr_start\n",
    "        elif num_epoch < lr_up_epoch + lr_sustain_epoch:  # 學習率保持不變\n",
    "            lr = max_lr\n",
    "        else:  # 指數下降\n",
    "            lr = (max_lr - lr_start) * lr_exp ** (num_epoch - lr_up_epoch - lr_sustain_epoch) + lr_start\n",
    "        for param_group in optimzer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        return optimzer\n",
    "#参數設置\n",
    "def parse_opt():\n",
    "    parser=argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--weights\",type=str,default=\"./model/efficientnet-b5-b6417697.pth\",help='initial weights path')#預訓練模型路徑\n",
    "    parser.add_argument(\"--img-dir\",type=str,default=\"./cifar_100\\cifar100_10percent\",help=\"train image path\") #數據集的路徑\n",
    "    parser.add_argument(\"--imgsz\",type=int,default=224,help=\"image size\") #圖像尺寸\n",
    "    parser.add_argument(\"--epochs\",type=int,default=50,help=\"train epochs\")#訓練批次\n",
    "    parser.add_argument(\"--batch-size\",type=int,default=8,help=\"train batch-size\") #batch-size\n",
    "    parser.add_argument(\"--class_num\",type=int,default=100,help=\"class num\") #類別數\n",
    "    parser.add_argument(\"--lr\",type=float,default=0.0005,help=\"Init lr\") #學習率初始值\n",
    "    parser.add_argument(\"--m\",type=float,default=0.9,help=\"optimer momentum\") #動量\n",
    "    parser.add_argument(\"--save-dir\",type=str,default=\"./weight\",help=\"save models dir\")#保存模型路徑\n",
    "    opt=parser.parse_known_args()[0]\n",
    "    return opt\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    opt=parse_opt()\n",
    "    models=Efficientnet_train(opt)\n",
    "    models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'efficientnet_pytorch.model.EfficientNet'>\n",
      "photo number :  10000\n",
      "Loss: 3.2281 Acc: 0.4521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Taka\\anaconda3\\envs\\taka1\\lib\\site-packages\\ipykernel_launcher.py:120: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "#用訓練出的模型進行預測\n",
    "input_size = 224\n",
    "device = 'cuda'\n",
    "\n",
    "means = [0.485, 0.456, 0.406]\n",
    "stds = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "# Load Test images\n",
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor\n",
    "\n",
    "unorm = UnNormalize(mean = means, std = stds)\n",
    "\n",
    "\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    def __init__(self, *args):\n",
    "        super(ImageFolderWithPaths, self).__init__(*args)\n",
    "        self.trans = args[1]\n",
    "    def __len__(self):\n",
    "      return len(self.imgs)\n",
    "    def __getitem__(self, index):\n",
    "        img, label = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        \n",
    "        path = self.imgs[index][0]\n",
    "        return (img, label ,path)\n",
    "\n",
    "\n",
    "def loaddata(data_dir, batch_size, set_name, shuffle):\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(means, stds)\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(means, stds)\n",
    "        ]),\n",
    "        'test_class': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(means, stds)\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    image_datasets = {x: ImageFolderWithPaths(os.path.join(data_dir, x), data_transforms[x]) for x in [set_name]}\n",
    "    # num_workers=0 if CPU else = 1\n",
    "    dataset_loaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                                      batch_size=batch_size,\n",
    "                                                      shuffle=shuffle, num_workers=0) for x in [set_name]}\n",
    "    data_set_sizes = len(image_datasets[set_name])\n",
    "    return dataset_loaders, data_set_sizes\n",
    "\n",
    "\n",
    "\n",
    "def test_model(model, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    cont = 0\n",
    "    outPre = []\n",
    "    outLabel = []\n",
    "    dset_loaders, dset_sizes = loaddata(data_dir=data_dir, batch_size=batch_size, set_name = 'test_class',shuffle=False)\n",
    "    transform = T.ToPILImage()\n",
    "    for data in dset_loaders['test_class']:\n",
    "        inputs, labels, paths = data #path抓出被分類的圖片的原始路徑\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        \n",
    "        # GPU\n",
    "        inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        #計算預測結果entropy\n",
    "        entropy = 0\n",
    "        # for t in range(len(outputs.data)):\n",
    "        #     for t2 in range(len(outputs.data[t])):\n",
    "        #         entropy = entropy + (-1*( torch.log(outputs.data[t][t2]) * outputs.data[t][t2] ))\n",
    "\n",
    "\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        if cont == 0:\n",
    "            outPre = outputs.data.cpu()\n",
    "            outLabel = labels.data.cpu()\n",
    "        else:\n",
    "            outPre = torch.cat((outPre, outputs.data.cpu()), 0)\n",
    "            outLabel = torch.cat((outLabel, labels.data.cpu()), 0)\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        cont += len(labels)\n",
    "        acc = running_corrects/cont\n",
    "\n",
    "    print('photo number : ',dset_sizes)\n",
    "    print('Loss: {:.4f} Acc: {:.4f}'.format(running_loss / dset_sizes,\n",
    "                                            running_corrects.double() / dset_sizes))\n",
    "\n",
    "    return FUN.softmax(Variable(outPre)).data.numpy(), outLabel.numpy()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "    # Start Testing\n",
    "    net_name = 'efficientnet-b5'\n",
    "    data_dir = 'cifar_100'\n",
    "    save_dir = 'weight/0921'\n",
    "    modelft_file = save_dir + \"/\" + 'efficientb5_cifar100_50percent_just_good_model' + '.pth'\n",
    "    batch_size = 2\n",
    "\n",
    "    # GPU時\n",
    "    model_ft = efficientnet_pytorch.EfficientNet.from_name(net_name)\n",
    "    # 修改全連接層\n",
    "    num_ftrs = model_ft._fc.in_features\n",
    "    model_ft._fc = nn.Linear(num_ftrs, 100)\n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "    model_ft.load_state_dict(torch.load(modelft_file))\n",
    "    print(type(model_ft))\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "    outPre, outLabel = test_model(model_ft, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'efficientnet_pytorch.model.EfficientNet'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Taka\\anaconda3\\envs\\taka1\\lib\\site-packages\\ipykernel_launcher.py:105: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "#生成dict，內容 : ( 各類的cofidence , gt label  ) \n",
    "\n",
    "tensor = []\n",
    "label = []\n",
    "class_num = []\n",
    "\n",
    "input_size = 224\n",
    "device = 'cuda'\n",
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor\n",
    "means = [0.485, 0.456, 0.406]\n",
    "stds = [0.229, 0.224, 0.225]\n",
    "unorm = UnNormalize(mean = means, std = stds)\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    def __init__(self, *args):\n",
    "        super(ImageFolderWithPaths, self).__init__(*args)\n",
    "        self.trans = args[1]\n",
    "    def __len__(self):\n",
    "      return len(self.imgs)\n",
    "    def __getitem__(self, index):\n",
    "        img, label = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        \n",
    "        path = self.imgs[index][0]\n",
    "        return (img, label ,path)\n",
    "# Load Test images\n",
    "def loaddata(data_dir, batch_size, set_name, shuffle):\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(means, stds)\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(means, stds)\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    image_datasets = {x: ImageFolderWithPaths(os.path.join(data_dir, x), data_transforms[x]) for x in [set_name]}\n",
    "    # num_workers=0 if CPU else = 1\n",
    "    dataset_loaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                                      batch_size=batch_size,\n",
    "                                                      shuffle=shuffle, num_workers=0) for x in [set_name]}\n",
    "    data_set_sizes = len(image_datasets[set_name])\n",
    "    return dataset_loaders, data_set_sizes\n",
    "\n",
    "\n",
    "def test_model(model, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    cont = 0\n",
    "    outPre = []\n",
    "    outLabel = []\n",
    "    img_path = []\n",
    "    dset_loaders, dset_sizes = loaddata(data_dir=data_dir, batch_size=batch_size, set_name='val', shuffle=False)\n",
    "    transform = T.ToPILImage()\n",
    "    for data in dset_loaders['val']:\n",
    "        inputs, labels, paths = data #path抓出被分類的圖片的原始路徑\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        \n",
    "        # GPU\n",
    "        inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        tensor.append(outputs.data)\n",
    "\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "        class_num.append(labels)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        if cont == 0:\n",
    "            outPre = outputs.data.cpu()\n",
    "            outLabel = labels.data.cpu()\n",
    "        else:\n",
    "            outPre = torch.cat((outPre, outputs.data.cpu()), 0)\n",
    "            outLabel = torch.cat((outLabel, labels.data.cpu()), 0)\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        cont += len(labels)\n",
    "        acc = running_corrects/cont\n",
    "\n",
    "    return FUN.softmax(Variable(outPre)).data.numpy(), outLabel.numpy()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "    # Start Testing\n",
    "    net_name = 'efficientnet-b5'\n",
    "    data_dir = 'cifar_10\\cifar10_second_5percent_split'\n",
    "    save_dir = 'weight/0610'\n",
    "    modelft_file = save_dir + \"/\" + 'efficientb5_cifar10_10percent' + '.pth'\n",
    "    batch_size = 1\n",
    "\n",
    "    # GPU時\n",
    "    model_ft = efficientnet_pytorch.EfficientNet.from_name(net_name)\n",
    "    # 修改全連接層\n",
    "    num_ftrs = model_ft._fc.in_features\n",
    "    model_ft._fc = nn.Linear(num_ftrs, 10)\n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "    model_ft.load_state_dict(torch.load(modelft_file))\n",
    "    print(type(model_ft))\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "    outPre, outLabel = test_model(model_ft, criterion)\n",
    "\n",
    "# # tensor = torch.stack(tensor)\n",
    "# label = torch.stack(label)\n",
    "class_num = torch.stack(class_num)\n",
    "\n",
    "\n",
    "#製作訓練集(以5%的模型跑)\n",
    "# with open('pickle/cifar_val_tensor.pickle', 'wb') as f:\n",
    "#     pickle.dump(tensor, f)\n",
    "\n",
    "#製作label(以10%的模型跑)\n",
    "with open('pickle/cifar_val_label.pickle', 'wb') as f:\n",
    "    pickle.dump(tensor, f)\n",
    "\n",
    "#製作每筆data對應到的class的列表\n",
    "# with open('pickle/cifar_val_class_label.pickle', 'wb') as f:\n",
    "#     pickle.dump(class_num, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.6421e+00,  3.0447e-01, -6.9695e-01, -1.5140e-01, -8.7047e-01,\n",
      "         -7.7928e-01, -7.4363e-01, -1.0252e+00, -4.9470e-01,  4.7723e-01],\n",
      "        [ 2.6250e+00, -3.5314e-01, -5.1155e-01, -4.1791e-01, -5.2495e-01,\n",
      "         -1.8490e-01, -4.1576e-01, -6.0706e-01,  8.0143e-02,  6.6952e-01],\n",
      "        [ 5.1802e+00, -6.9600e-01, -2.5664e-02, -4.0577e-03, -1.3055e+00,\n",
      "         -8.8313e-01, -7.3957e-01, -1.2481e+00,  2.0464e-01,  2.1246e-02],\n",
      "        [ 3.6038e+00, -2.5990e-01,  1.5668e-01, -8.2306e-01, -4.0782e-01,\n",
      "         -6.1584e-01, -8.8105e-01, -9.5602e-01,  2.5508e-01,  3.7847e-01]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 4.5153, -0.1113, -0.6022, -0.5720, -1.2648, -0.3586, -0.5964, -1.2770,\n",
      "         -0.0112,  0.1757],\n",
      "        [ 5.1651, -0.8470, -0.7290, -0.9412, -0.8426, -0.0106, -1.0423, -1.4531,\n",
      "          0.2703,  0.0832],\n",
      "        [ 2.7483, -0.3633, -0.2387, -0.1087, -0.5100,  0.0830, -0.2539, -0.6474,\n",
      "         -0.2717,  0.0592],\n",
      "        [ 3.0937, -0.4380, -0.5149, -0.2293, -0.5986,  0.1423, -0.2704, -0.7063,\n",
      "         -0.5054,  0.3789]], device='cuda:0')\n",
      "tensor([[ 4.1958, -1.3905,  0.1737, -0.3689, -0.2179, -0.8950, -0.2429, -1.1684,\n",
      "          0.3514, -0.1380],\n",
      "        [ 4.4550, -0.5635, -1.3666,  0.1649, -1.3688, -0.3741, -1.0147, -1.0186,\n",
      "         -0.0466,  0.4403],\n",
      "        [ 3.6790, -0.1359, -0.4177, -0.5679, -0.8307,  0.1921, -0.6217, -0.8404,\n",
      "         -0.4534,  0.1099],\n",
      "        [ 3.9584, -0.3040, -0.7689, -0.7257, -0.5847, -0.0250, -0.9689, -0.8377,\n",
      "          0.2164, -0.0254]], device='cuda:0')\n",
      "tensor([[ 4.9743, -0.8561, -1.7560,  1.2749, -2.1760, -0.0380,  0.1101, -0.6548,\n",
      "          0.2592, -0.7009],\n",
      "        [ 5.7679, -0.4009, -0.6743,  0.1777, -0.6186, -0.6964, -1.7678, -1.1777,\n",
      "          0.5778, -1.1578],\n",
      "        [ 2.8110, -0.3870, -0.1880, -0.6803, -0.2730, -0.2132, -0.3213, -0.9646,\n",
      "          0.0997,  0.5428],\n",
      "        [ 5.6739, -0.8299, -1.0376, -0.9649, -0.2790,  0.0139, -0.8276, -1.3546,\n",
      "         -0.2825, -0.0550]], device='cuda:0')\n",
      "tensor([[ 3.1898, -0.7134, -0.3491, -0.3406, -0.8692, -0.1579, -0.5015, -0.7127,\n",
      "         -0.2145,  0.3813],\n",
      "        [ 4.0177, -0.6773, -0.5487, -0.0300, -0.8536, -0.0119, -0.5384, -1.1817,\n",
      "         -0.3560,  0.4261],\n",
      "        [ 2.8840, -0.4447, -0.6096, -0.0476, -0.1408, -0.0174, -0.4054, -0.6213,\n",
      "          0.0748, -0.0642],\n",
      "        [ 3.6167, -0.4417, -0.1047, -0.6664, -0.7828, -0.3289, -0.5472, -0.8828,\n",
      "         -0.0472,  0.2386]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#建線性模型dataset\n",
    "\n",
    "with open('train_tensor.pickle', 'rb') as f:\n",
    "    train_tensor = pickle.load(f)\n",
    "with open('train_label.pickle', 'rb') as f:\n",
    "    train_label = pickle.load(f)\n",
    "with open('val_tensor.pickle', 'rb') as f:\n",
    "    val_tensor = pickle.load(f)\n",
    "with open('val_label.pickle', 'rb') as f:\n",
    "    val_label = pickle.load(f)\n",
    "\n",
    "with open('train_class_label.pickle', 'rb') as f:\n",
    "    train_class_label = pickle.load(f)\n",
    "\n",
    "with open('val_class_label.pickle', 'rb') as f:\n",
    "    val_class_label = pickle.load(f)\n",
    "\n",
    "class_number = 10\n",
    "batch_size = 4\n",
    "\n",
    "'''按batch size包裝資料'''\n",
    "register_3 = []\n",
    "register_4 = []\n",
    "train_tensor_list= []\n",
    "train_label_list= []\n",
    "for class_name in range(class_number):\n",
    "    count = 0\n",
    "    register_1 = []\n",
    "    register_2 = []\n",
    "    for t in range(len(train_tensor)):\n",
    "        if int(train_class_label[t]) == class_name:\n",
    "            register_1.append(train_tensor[t])\n",
    "            register_2.append(train_label[t])\n",
    "            count+=1\n",
    "        if count  == batch_size:\n",
    "            a = torch.cat(register_1)\n",
    "            b = torch.cat(register_2)\n",
    "            register_1 = []\n",
    "            register_2 = []\n",
    "            register_3.append(a)\n",
    "            register_4.append(b)\n",
    "            count = 0\n",
    "    a = torch.stack(register_3)\n",
    "    b = torch.stack(register_4)\n",
    "    train_tensor_list.append(a)\n",
    "    train_label_list.append(b)\n",
    "    register_3 = []\n",
    "    register_4 = []\n",
    "\n",
    "register_3 = []\n",
    "register_4 = []\n",
    "val_tensor_list= []\n",
    "val_label_list= []\n",
    "for class_name in range(class_number):\n",
    "    count = 0\n",
    "    register_1 = []\n",
    "    register_2 = []\n",
    "    for t in range(len(val_tensor)):\n",
    "        if int(val_class_label[t]) == class_name:\n",
    "            register_1.append(val_tensor[t])\n",
    "            register_2.append(val_label[t])\n",
    "            count+=1\n",
    "        if count  == batch_size:\n",
    "            a = torch.cat(register_1)\n",
    "            b = torch.cat(register_2)\n",
    "            register_1 = []\n",
    "            register_2 = []\n",
    "            register_3.append(a)\n",
    "            register_4.append(b)\n",
    "            count = 0\n",
    "    a = torch.stack(register_3)\n",
    "    b = torch.stack(register_4)\n",
    "    val_tensor_list.append(a)\n",
    "    val_label_list.append(b)\n",
    "    register_3 = []\n",
    "    register_4 = []\n",
    "\n",
    "for i, images in enumerate(val_label_list[0]):\n",
    "    print(images)\n",
    "for i, images in enumerate(val_label_list[0]):\n",
    "    print(images)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型對second 5 percent的預測結果訓練一個線性模型\n",
    "\n",
    "with open('pickle/cifar_train_tensor.pickle', 'rb') as f:\n",
    "    train_tensor = pickle.load(f)\n",
    "with open('pickle/cifar_train_label.pickle', 'rb') as f:\n",
    "    train_label = pickle.load(f)\n",
    "with open('pickle/cifar_val_tensor.pickle', 'rb') as f:\n",
    "    val_tensor = pickle.load(f)\n",
    "with open('pickle/cifar_val_label.pickle', 'rb') as f:\n",
    "    val_label = pickle.load(f)\n",
    "\n",
    "with open('pickle/cifar_train_class_label.pickle', 'rb') as f:\n",
    "    train_class_label = pickle.load(f)\n",
    "\n",
    "with open('pickle/cifar_val_class_label.pickle', 'rb') as f:\n",
    "    val_class_label = pickle.load(f)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''讓數據集可以叠代'''\n",
    "batch_size = 8\n",
    "n_iters = 20000\n",
    "\n",
    "'''定義模型'''\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "'''實例化模型'''\n",
    "class_number = 10\n",
    "input_dim = class_number\n",
    "output_dim = 1\n",
    "\n",
    "model = LogisticRegressionModel(input_dim, output_dim)\n",
    "model = model.to(device)\n",
    "\n",
    "'''定義損失計算方式'''\n",
    "cauculate = torch.nn.MSELoss(reduce = True,size_average = True)\n",
    "\n",
    "learning_rate = 0.0005\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "'''按batch size包裝資料'''\n",
    "register_3 = []\n",
    "register_4 = []\n",
    "train_tensor_list= []\n",
    "train_label_list= []\n",
    "for class_name in range(class_number):\n",
    "    count = 0\n",
    "    register_1 = []\n",
    "    register_2 = []\n",
    "    for t in range(len(train_tensor)):\n",
    "        \n",
    "        numpy = FUN.softmax(Variable(train_tensor[t])).data.cpu().numpy()#把input從confidence轉為機率\n",
    "        train_tensor[t] = torch.from_numpy(numpy)\n",
    "        numpy2 = FUN.softmax(Variable(train_label[t])).data.cpu().numpy()#把input從confidence轉為機率\n",
    "        train_label[t] = torch.from_numpy(numpy2)\n",
    "\n",
    "        if int(train_class_label[t]) == class_name:\n",
    "            register_1.append(train_tensor[t])\n",
    "            register_2.append(train_label[t])\n",
    "            count+=1\n",
    "        if count  == batch_size:\n",
    "            a = torch.cat(register_1)\n",
    "            b = torch.cat(register_2)\n",
    "            register_1 = []\n",
    "            register_2 = []\n",
    "            register_3.append(a)\n",
    "            register_4.append(b)\n",
    "            count = 0\n",
    "    a = torch.stack(register_3)\n",
    "    b = torch.stack(register_4)\n",
    "    train_tensor_list.append(a)\n",
    "    train_label_list.append(b)\n",
    "    register_3 = []\n",
    "    register_4 = []\n",
    "\n",
    "register_3 = []\n",
    "register_4 = []\n",
    "val_tensor_list= []\n",
    "val_label_list= []\n",
    "for class_name in range(class_number):\n",
    "    count = 0\n",
    "    register_1 = []\n",
    "    register_2 = []\n",
    "    for t in range(len(val_tensor)):\n",
    "\n",
    "        numpy = FUN.softmax(Variable(val_tensor[t])).data.cpu().numpy()#把input從confidence轉為機率\n",
    "        val_tensor[t] = torch.from_numpy(numpy)\n",
    "        numpy2 = FUN.softmax(Variable(val_label[t])).data.cpu().numpy()#把input從confidence轉為機率\n",
    "        val_label[t] = torch.from_numpy(numpy2)\n",
    "\n",
    "        if int(val_class_label[t]) == class_name:\n",
    "            register_1.append(val_tensor[t])\n",
    "            register_2.append(val_label[t])\n",
    "            count+=1\n",
    "        if count  == batch_size:\n",
    "            a = torch.cat(register_1)\n",
    "            b = torch.cat(register_2)\n",
    "            register_1 = []\n",
    "            register_2 = []\n",
    "            register_3.append(a)\n",
    "            register_4.append(b)\n",
    "            count = 0\n",
    "    a = torch.stack(register_3)\n",
    "    b = torch.stack(register_4)\n",
    "    val_tensor_list.append(a)\n",
    "    val_label_list.append(b)\n",
    "    register_3 = []\n",
    "    register_4 = []\n",
    "\n",
    "\n",
    "\n",
    "'''訓練次數'''\n",
    "save_dir = 'linear_weight'\n",
    "\n",
    "for class_num in range(class_number):\n",
    "    print('model for class '+str(class_num))\n",
    "    num_epochs = n_iters / (len(train_tensor_list[class_num]))\n",
    "    num_epochs = int(num_epochs)\n",
    "    iter = 0\n",
    "    best_loss = 6\n",
    "    for epoch in range(num_epochs):\n",
    "        count = 0\n",
    "        for i, images in enumerate(train_tensor_list[class_num]):\n",
    "            register_1=[]\n",
    "            for b_size in range(batch_size):\n",
    "                a = train_label_list[class_num][count][b_size][class_num]\n",
    "                a = a.unsqueeze(0)\n",
    "                register_1.append(a)\n",
    "\n",
    "            labels = torch.stack(register_1)\n",
    "            labels = Variable(labels)\n",
    "\n",
    "            count+=1\n",
    "            #梯度置零\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #計算輸出\n",
    "            outputs = model(images)\n",
    "            # print(images,'--------',outputs)\n",
    "            # print(labels)\n",
    "            \n",
    "            #計算損失，內部會自動softmax然後進行Crossentropy\n",
    "            loss = cauculate(outputs.float(),labels.float())\n",
    "            #反向傳播\n",
    "            loss.backward()\n",
    "            \n",
    "            #更新參數\n",
    "            optimizer.step()\n",
    "            \n",
    "            iter += 1\n",
    "            \n",
    "            if iter % 500 == 0:\n",
    "                #計算準確度\n",
    "                all = 0\n",
    "                count2 = 0\n",
    "                for images in val_tensor_list[class_num]:\n",
    "                    register_1=[]\n",
    "                    for b_size in range(batch_size):\n",
    "                        a = val_label_list[class_num][count2][b_size][class_num]\n",
    "                        a = a.unsqueeze(0)\n",
    "                        register_1.append(a)\n",
    "\n",
    "                    labels = torch.stack(register_1)\n",
    "                    labels = Variable(labels)\n",
    "                    outputs = model(images)\n",
    "                    loss = cauculate(outputs.float(),labels.float())\n",
    "                    all = loss+all\n",
    "                    count2+=1\n",
    "                loss = all/count2\n",
    "                if loss < best_loss:\n",
    "                    best_loss = loss\n",
    "                    start_time=(time.strftime(\"%m%d\",time.localtime()))\n",
    "                    save_weight=save_dir+os.sep+start_time #保存路徑\n",
    "                    os.makedirs(save_weight,exist_ok=True)\n",
    "                    torch.save(model.state_dict(), save_weight + os.sep +'cifar_'+str(class_num)+\".pth\")\n",
    "\n",
    "                    \n",
    "                # Print Loss\n",
    "                print('Iteration: {}. Loss: {}. '.format(iter, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Taka\\anaconda3\\envs\\taka1\\lib\\site-packages\\ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0616, 0.0301, 0.0243, 0.2599, 0.0312, 0.0336, 0.4237, 0.0205, 0.0142,\n",
      "         0.1009]], device='cuda:0')\n",
      "tensor([0.8162, 0.2865, 0.1526, 0.1421, 0.1411, 0.1410, 0.1410, 0.1410, 0.1410,\n",
      "        0.1410])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Taka\\anaconda3\\envs\\taka1\\lib\\site-packages\\ipykernel_launcher.py:74: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_og :  0.7417142857142857 ---- count :  1298  acc :  0.1 ---- count :  175  all :  1750\n"
     ]
    }
   ],
   "source": [
    "#各個線性模型產出output\n",
    "with open('pickle/cifar_train_tensor.pickle', 'rb') as f:\n",
    "    train_tensor = pickle.load(f)\n",
    "with open('pickle/cifar_train_label.pickle', 'rb') as f:\n",
    "    train_label = pickle.load(f)\n",
    "with open('pickle/cifar_val_tensor.pickle', 'rb') as f:\n",
    "    val_tensor = pickle.load(f)\n",
    "with open('pickle/cifar_val_label.pickle', 'rb') as f:\n",
    "    val_label = pickle.load(f)\n",
    "\n",
    "with open('pickle/cifar_train_class_label.pickle', 'rb') as f:\n",
    "    class_label = pickle.load(f)\n",
    "\n",
    "with open('pickle/cifar_val_class_label.pickle', 'rb') as f:\n",
    "    val_class_label = pickle.load(f)\n",
    "\n",
    "    '''定義模型'''\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "'''實例化模型'''\n",
    "class_number = 10\n",
    "input_dim = class_number\n",
    "output_dim = 1\n",
    "device = 'cuda'\n",
    "weight_dir = 'linear_weight/0610'\n",
    "weight_path = os.listdir(weight_dir)\n",
    "model_file = []\n",
    "\n",
    "for t in range(len(weight_path)):\n",
    "    path = weight_dir + '/' + weight_path[t]\n",
    "    model_file.append(path)\n",
    "\n",
    "tensor_register = []\n",
    "\n",
    "model = LogisticRegressionModel(input_dim, output_dim)\n",
    "\n",
    "for t in range(len(train_tensor)):\n",
    "\n",
    "    register = []\n",
    "\n",
    "    numpy = FUN.softmax(Variable(train_tensor[t])).data.cpu().numpy()#把input從confidence轉為機率\n",
    "    train_tensor[t] = torch.from_numpy(numpy)\n",
    " \n",
    "    for model_num in range(len(model_file)):\n",
    "        model.load_state_dict(torch.load(model_file[model_num]))\n",
    "        model = model.to(device)\n",
    "        register.append(model(train_tensor[t]))\n",
    "    new_tensor = torch.tensor(register)\n",
    "    tensor_register.append(new_tensor)\n",
    "new_tensor = torch.stack(tensor_register)\n",
    "\n",
    "print(train_tensor[1600])\n",
    "print(new_tensor[1600])\n",
    "\n",
    "class_num = []\n",
    "class_num_og = []\n",
    "for t in range((len(new_tensor))):\n",
    "\n",
    "    class_num.append(torch.max(new_tensor[t],0)[1])\n",
    "class_num = torch.stack(class_num)\n",
    "class_num = class_num.to(device)\n",
    "class_label = class_label.view(-1)\n",
    "\n",
    "\n",
    "for t in range((len(train_tensor))):\n",
    "\n",
    "    numpy = FUN.softmax(Variable(train_tensor[t])).data.cpu().numpy()#把input從confidence轉為機率\n",
    "    train_tensor[t] = torch.from_numpy(numpy)\n",
    "\n",
    "    s = train_tensor[t].squeeze()\n",
    "    class_num_og.append(torch.max(s,0)[1])\n",
    "class_num_og = torch.stack(class_num_og)\n",
    "class_num_og = class_num_og.to(device)\n",
    "\n",
    "correct = 0\n",
    "for t in range(len(class_num)):\n",
    "    if  class_num[t] == class_label[t]:\n",
    "        correct +=1\n",
    "\n",
    "correct2 = 0\n",
    "for t in range(len(class_num_og)):\n",
    "    if  class_num_og[t] == class_label[t]:\n",
    "        correct2 +=1\n",
    "\n",
    "acc = correct/len(class_num)\n",
    "acc2 = correct2/len(class_num_og)\n",
    "print('acc_og : ',acc2,'---- count : ',correct2,' acc : ',acc,'---- count : ',correct ,' all : ',len(class_num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'efficientnet_pytorch.model.EfficientNet'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Taka\\anaconda3\\envs\\taka1\\lib\\site-packages\\ipykernel_launcher.py:111: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "#預測100% data\n",
    "#生成dict，內容 : ( 各類的cofidence , gt label  ) \n",
    "\n",
    "tensor = []\n",
    "label = []\n",
    "class_num = []\n",
    "image_path = []\n",
    "\n",
    "input_size = 224\n",
    "device = 'cuda'\n",
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor\n",
    "means = [0.485, 0.456, 0.406]\n",
    "stds = [0.229, 0.224, 0.225]\n",
    "unorm = UnNormalize(mean = means, std = stds)\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    def __init__(self, *args):\n",
    "        super(ImageFolderWithPaths, self).__init__(*args)\n",
    "        self.trans = args[1]\n",
    "    def __len__(self):\n",
    "      return len(self.imgs)\n",
    "    def __getitem__(self, index):\n",
    "        img, label = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        path = self.imgs[index][0]\n",
    "        return (img, label ,path)\n",
    "# Load Test images\n",
    "def loaddata(data_dir, batch_size, set_name, shuffle):\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(means, stds)\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(means, stds)\n",
    "        ]),\n",
    "        'cifar10': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(means, stds)\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    image_datasets = {x: ImageFolderWithPaths(os.path.join(data_dir, x), data_transforms[x]) for x in [set_name]}\n",
    "    # num_workers=0 if CPU else = 1\n",
    "    dataset_loaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                                      batch_size=batch_size,\n",
    "                                                      shuffle=shuffle, num_workers=0) for x in [set_name]}\n",
    "    data_set_sizes = len(image_datasets[set_name])\n",
    "    return dataset_loaders, data_set_sizes\n",
    "\n",
    "\n",
    "def test_model(model, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    cont = 0\n",
    "    outPre = []\n",
    "    outLabel = []\n",
    "    dset_loaders, dset_sizes = loaddata(data_dir=data_dir, batch_size=batch_size, set_name='cifar10', shuffle=False)\n",
    "    transform = T.ToPILImage()\n",
    "    for data in dset_loaders['cifar10']:\n",
    "        inputs, labels, paths = data #path抓出被分類的圖片的原始路徑\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        image_path.append(paths)\n",
    "        # GPU\n",
    "        inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        class_num.append(labels)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        tensor.append(outputs.data)\n",
    "        label.append(outputs.data)\n",
    "\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        if cont == 0:\n",
    "            outPre = outputs.data.cpu()\n",
    "            outLabel = labels.data.cpu()\n",
    "        else:\n",
    "            outPre = torch.cat((outPre, outputs.data.cpu()), 0)\n",
    "            outLabel = torch.cat((outLabel, labels.data.cpu()), 0)\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        cont += len(labels)\n",
    "        acc = running_corrects/cont\n",
    "\n",
    "    return FUN.softmax(Variable(outPre)).data.numpy(), outLabel.numpy()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "    # Start Testing\n",
    "    net_name = 'efficientnet-b5'\n",
    "    data_dir = 'cifar_10'\n",
    "    save_dir = 'weight/0610'\n",
    "    modelft_file = save_dir + \"/\" + 'efficientb5_cifar10_10percent' + '.pth'\n",
    "    batch_size = 1\n",
    "\n",
    "    # GPU時\n",
    "    model_ft = efficientnet_pytorch.EfficientNet.from_name(net_name)\n",
    "    # 修改全連接層\n",
    "    num_ftrs = model_ft._fc.in_features\n",
    "    model_ft._fc = nn.Linear(num_ftrs, 10)\n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "    model_ft.load_state_dict(torch.load(modelft_file))\n",
    "    print(type(model_ft))\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "    outPre, outLabel = test_model(model_ft, criterion)\n",
    "\n",
    "# tensor = torch.stack(tensor)\n",
    "# label = torch.stack(label)\n",
    "class_num = torch.stack(class_num)\n",
    "print(len(class_num))\n",
    "print(len(tensor))\n",
    "\n",
    "#製作訓練集\n",
    "# with open('pickle\\cifar_data/testset_tensor.pickle', 'wb') as f:\n",
    "#     pickle.dump(tensor, f)\n",
    "\n",
    "#製作label\n",
    "with open('pickle\\cifar_data/alldata_result.pickle', 'wb') as f:\n",
    "    pickle.dump(label, f)\n",
    "\n",
    "# 製作每筆data對應到的class的列表\n",
    "with open('pickle\\cifar_data/alldata_class_label.pickle', 'wb') as f:\n",
    "    pickle.dump(class_num, f)\n",
    "\n",
    "with open('pickle\\cifar_data/alldata_img_path.pickle', 'wb') as f:\n",
    "    pickle.dump(image_path, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#依照entropy挑出50% data\n",
    "with open('100percent_train_tensor.pickle', 'rb') as f:\n",
    "    train_tensor = pickle.load(f)\n",
    "\n",
    "with open('100percent_val_tensor.pickle', 'rb') as f:\n",
    "    val_tensor = pickle.load(f)\n",
    "\n",
    "with open('100percent_train_img_path.pickle', 'rb') as f:\n",
    "    train_image_path = pickle.load(f)\n",
    "\n",
    "with open('100percent_val_img_path.pickle', 'rb') as f:\n",
    "    val_image_path = pickle.load(f)\n",
    "\n",
    "list = []\n",
    "for  t in range(len(train_tensor)):\n",
    "    list.append(train_tensor[t])\n",
    "for  t in range(len(val_tensor)):\n",
    "    list.append(val_tensor[t])\n",
    "tensor = torch.stack(list)\n",
    "\n",
    "list2 = []\n",
    "for t in range(len(train_image_path)):\n",
    "    list2.append(train_image_path[t])\n",
    "for t in range(len(val_image_path)):\n",
    "    list2.append(val_image_path[t])\n",
    "image_path = list2\n",
    "\n",
    "'''算entropy'''\n",
    "def entropy(input):\n",
    "    all = 0\n",
    "    for t in range(len(input)):\n",
    "        if input[t]>=0:\n",
    "            en = -(input[t]*math.log(input[t],2))\n",
    "            all = all+en\n",
    "    return all\n",
    "\n",
    "'''定義模型'''\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "'''實例化模型'''\n",
    "class_number = 10\n",
    "input_dim = class_number\n",
    "output_dim = 1\n",
    "device = 'cuda'\n",
    "weight_dir = 'linear_weight/0606'\n",
    "weight_path = os.listdir(weight_dir)\n",
    "model_file = []\n",
    "\n",
    "for t in range(len(weight_path)):\n",
    "    path = weight_dir + '/' + weight_path[t]\n",
    "    model_file.append(path)\n",
    "\n",
    "tensor_register = []\n",
    "\n",
    "model = LogisticRegressionModel(input_dim, output_dim)\n",
    "\n",
    "for t in range(len(tensor)):\n",
    "\n",
    "    register = []\n",
    "\n",
    "    for model_num in range(len(model_file)):\n",
    "        model.load_state_dict(torch.load(model_file[model_num]))\n",
    "        model = model.to(device)\n",
    "        register.append(model(tensor[t]))\n",
    "\n",
    "    new_tensor = torch.tensor(register)\n",
    "    tensor_register.append(new_tensor)\n",
    "\n",
    "new_tensor = torch.stack(tensor_register)\n",
    "\n",
    "img_save_dir = '50_percent/50_percent_data' \n",
    "img_dir = 'imagenette_all'\n",
    "all_en = []\n",
    "for t in range(len(new_tensor)):\n",
    "    odds = FUN.softmax(Variable(new_tensor[t])).data.numpy()\n",
    "    data_entropy = entropy(odds)\n",
    "    all_en.append(data_entropy)\n",
    "sort = sorted(range(len(all_en)) , reverse = True,key = lambda k : all_en[k])\n",
    "img_dir_list=glob.glob(img_dir+os.sep+\"*\")#獲取每個類别所在的路徑（一個類别對應一個文件夾）\n",
    "for class_dir in img_dir_list:\n",
    "    class_name=class_dir.split(os.sep)[-1] #獲取當前類别\n",
    "    save_train=img_save_dir+os.sep+os.sep+class_name\n",
    "    save_val=img_save_dir+os.sep+os.sep+class_name\n",
    "    os.makedirs(save_train,exist_ok=True)\n",
    "    os.makedirs(save_val,exist_ok=True) #建立對應的文件夾\n",
    "\n",
    "for t in range(int(len(sort)/2)):\n",
    "    p = re.sub(\"\\,\",\"\",str(image_path [sort[t]]))\n",
    "    p = re.sub(\"\\(\",\"\",p)\n",
    "    p = re.sub(\"\\)\",\"\",p)\n",
    "    p = re.sub(\"\\'\",\"\",p)\n",
    "    split = p.split('\\\\')\n",
    "\n",
    "    img = cv2.imread(p)\n",
    "    cv2.imwrite(img_save_dir+'/'+ split[4]+'/'+split[6], img)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成CIFAR10資料集\n",
    "\n",
    "\n",
    "\n",
    "# 生成訓練集圖片，如果需要png格式，只需要改圖片字尾名即可。\n",
    "for j in range(1, 6):\n",
    "    dataName = \"cifar-10-batches-py/data_batch_\" + str(j)  # 讀取當前目錄下的data_batch12345檔案，dataName其實也是data_batch檔案的路徑，本文和指令碼檔案在同一目錄下。\n",
    "    Xtr = unpickle(dataName)\n",
    "    print(dataName + \" is loading...\")\n",
    "\n",
    "    for i in range(0, 10000):\n",
    "        img = np.reshape(Xtr['data'][i], (3, 32, 32))  # Xtr['data']為圖片二進位制資料\n",
    "        img = img.transpose(1, 2, 0)  # 讀取image\n",
    "        picName = 'cifar_10/train/' + str(Xtr['labels'][i]) + '_' + str(i + (j - 1)*10000) + '.jpg'  # Xtr['labels']為圖片的標籤，值範圍0-9，本文中，train資料夾需要存在，並與指令碼檔案在同一目錄下。\n",
    "        imsave(picName, img)\n",
    "    print(dataName + \" loaded.\")\n",
    "\n",
    "print(\"test_batch is loading...\")\n",
    "\n",
    "# 生成測試集圖片\n",
    "testXtr = unpickle(\"cifar-10-batches-py/test_batch\")\n",
    "for i in range(0, 10000):\n",
    "    img = np.reshape(testXtr['data'][i], (3, 32, 32))\n",
    "    img = img.transpose(1, 2, 0)\n",
    "    picName = 'cifar_10/test/' + str(testXtr['labels'][i]) + '_' + str(i) + '.jpg'\n",
    "    imsave(picName, img)\n",
    "print(\"test_batch loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#測試於CIFAR10 中的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickle\\cifar_data/testset_result.pickle', 'rb') as f:\n",
    "    result = pickle.load(f)\n",
    "\n",
    "with open('pickle\\cifar_data/testset_class_label.pickle', 'rb') as f:\n",
    "    label = pickle.load(f)\n",
    "\n",
    "with open('pickle\\cifar_data/testset_img_path.pickle', 'rb') as f:\n",
    "    path = pickle.load(f)\n",
    "\n",
    "model_path = 'linear_weight/cifar/model0.pth'\n",
    "\n",
    "device = 'cuda'\n",
    "MyResModel = LSTM_FCN(input_dim=1, hidden_dim=16, output_dim=5, layers=1).to(device)\n",
    "MyResModel.init_model()\n",
    "MyResModel.load_state_dict(torch.load(model_path))\n",
    "MyResModel = MyResModel.to(device)\n",
    "\n",
    "numpy = FUN.softmax(Variable(result[5])).data.cpu().numpy()\n",
    "tensor = torch.tensor(numpy)\n",
    "outputs = MyResModel(tensor)\n",
    "print(outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "908abd7e78fd4d71ba1be92795635fd82be5080a16e3cc7c1eae8bbfec458fa8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
